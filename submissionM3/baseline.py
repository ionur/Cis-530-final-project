from sklearn.feature_extraction import DictVectorizer
from sklearn.metrics import precision_recall_fscore_support

from sklearn.linear_model import Perceptron
from sklearn.linear_model import SGDClassifier
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import PassiveAggressiveClassifier
from sklearn.svm import LinearSVC
import pickle
from collections import OrderedDict 
import string
import datetime

def isApostrophePresent(word):
    if "'" in word:
        return True
    return False

  
def isDashPresent(word):
    if "-" in word:
        return True
    return False

def oneDigit(word):
    num = 0
    for l in word:
      if l.isdigit():
        num +=1
    if num == 1:
      return True
    else:
      return False

def twoDigits(word):
    num = 0
    for l in word:
      if l.isdigit():
        num +=1
    if num == 2:
      return True
    else:
      return False
    
def threeDigits(word):
    num = 0
    for l in word:
      if l.isdigit():
        num +=1
    if num == 3:
      return True
    else:
      return False
    
def fiveDigits(word):
    num = 0
    for l in word:
      if l.isdigit():
        num +=1
    if num == 5:
      return True
    else:
      return False
    
def sixDigits(word):
    num = 0
    for l in word:
      if l.isdigit():
        num +=1
    if num == 6:
      return True
    else:
      return False
    
def sevenDigits(word):
    num = 0
    for l in word:
      if l.isdigit():
        num +=1
    if num == 7:
      return True
    else:
      return False
    
def nineDigits(word):
    num = 0
    for l in word:
      if l.isdigit():
        num +=1
    if num == 9:
      return True
    else:
      return False
    
def fax(word):
    if "fax" in word.lower():
      return True
    else:
      return False

def isAge(word):
  if "edad" in word.lower() or "aÃ±os" in word.lower():
    return True
  
  return False

    
def hasPunctuation(word):
  #This might return a lot of false positives
  
  for letter in word:
    if( letter  in string.punctuation):
      return True
    
  return False


def isRoman(word):
  #This might return a lot of false positives
  romans = ['I','V','M','L','X','D','C']
  
  for letter in word:
    if( letter not in romans):
      return False
    
  return True

def isDigit(word):
  for letter in word:
    if not letter.isdigit():
      return False
    
  return True

def getfeats(word, postag, o):
    """ This takes the word in question and
    the offset with respect to the instance
    word """
    o = str(o)
    features = [
        (o + 'word', word), #0
        # TODO: add more features here.
        
        (o + 'word.len', len(word) ), #1
        (o + 'oneDigit', oneDigit(word)), #2
        (o + 'twoDigits', twoDigits(word)), #3
        (o + 'threeDigits', threeDigits(word)), #4
        (o + 'fiveDigits', fiveDigits(word)), #5
        (o + 'sixDigits', sixDigits(word)), #6
        (o + 'sevenDigits', sevenDigits(word)), #7
        (o + 'nineDigits', nineDigits(word)), #8
        (o + 'word.isupper', any(letter.isupper() for letter in word)), #9
        (o + 'hasPunctuation', hasPunctuation(word)), #10
        (o + 'isRoman', isRoman(word)), #11
        (o + 'age', isAge(word)), #12
        (o + 'isupper', word.isupper()), #13
        (o + 'islower', word.islower()), #14
        (o + 'isApostrophePresent', isApostrophePresent(word)), #15
        (o + 'isDashPresent', isDashPresent(word)), #16
        (o + 'fax', fax(word)) #17
    ]
    return features

def word2features(sent, i):
    """ The function generates all features
    for the word at position i in the
    sentence."""
    features = []
    # the window around the token
    featlist = [('bias', 1.0)]
    features.extend(featlist)

    for o in [-1,0,1,2]:
        if i+o >= 0 and i+o < len(sent):
            word = sent[i+o][0]
            postag = "unknown"
            featlist = getfeats(word, postag, o)
            features.extend(featlist)
        elif i+o<0:
            featlist = [('BOS', 1)]
            features.extend(featlist)
        else:
            featlist = [('EOS', 1)]
            features.extend(featlist)    
    return dict(features)

#create an .ann format for predictions generated by the model in ner tag format
def createAnnFormat(preprocess_dict, y_pred, pathRead, pathOut):  
    j = 0
    for docId, v in preprocess_dict.items():
        print('Generating .ann for ',docId)
        txt_start_end = ""
        tmp_tags=[]
        curr_tag = ""
        
        for sent in v:
          for item in sent:
            word = item[0]
            word_start= item[2]
            word_end = word_start + len(word) - 1
            pred = y_pred[j]   

            #if prediction is a beginning, add the tag to the tag list
            if pred[0:2] == "B-":
              if txt_start_end != "":
                tmp_tags.append((txt_start_end,curr_tag))
                txt_start_end= ""
              curr_tag= pred[2:]
              txt_start_end +=""+str(word_start)+"-"+str(word_end)+","
            #if it is a contuniation keep adding 
            elif pred[0:2] == "I-":
              txt_start_end +=""+str(word_start)+"-"+str(word_end)+","
            j += 1
        if txt_start_end != "":
          tmp_tags.append((txt_start_end,curr_tag))
          txt_start_end= ""  
        #we might be missing some chars in between values, so parse the data and 
        #get sentence matching that                        
        with open(pathRead+docId+".txt", "r") as f:                                                   
          complete_doc = f.read()       

        #now for all the text, get their exact match and create tags
        tags = []
        t_count = 1                        
        for i, i_tag in tmp_tags:
          splits = i.split(",")[:-1]
          beginning_split = splits[0].split("-")                 
          real_start = int(beginning_split[0])                      
          if len(splits) ==1:                  
            real_end = int(beginning_split[1])+1
          else:
            end_split = splits[len(splits)-1].split("-")
            real_end = int(end_split[1])+1
          text_appearing = complete_doc[real_start:real_end].split("\n")[0]
          tags.append("T"+str(t_count)+"\t"+i_tag+" "+str(real_start)+" "+str(real_end)+"\t"+ text_appearing)
          t_count += 1
        #now output all these
        with open(pathOut+docId+".ann", "w") as out:
          for i in tags:
            out.write(i+"\n")

if __name__ == "__main__":
  
    # Load the training data
    file = open('./train_word_ner_startidx_dict.pickle','rb')
    train_dict = pickle.load(file)
    train_dict = OrderedDict(train_dict)    
    file.close()
    
    train_sents = []
    
    for k, v in train_dict.items():
      train_sents.extend(v)

    print("train_sents len= ", len(train_sents))

    file = open('./dev_word_ner_startidx_dict.pickle','rb')
    dev_dict = pickle.load(file)
    dev_dict = OrderedDict(dev_dict)
    file.close()
    
    dev_sents = []
    for k, v in dev_dict.items():
      dev_sents.extend(v)
    
    print("dev_sents len= ", len(dev_sents))
      
    file = open('./test_word_ner_startidx_dict.pickle','rb')
    test_dict = pickle.load(file)
    test_dict = OrderedDict(test_dict)
    file.close()
    
    test_sents = []
    for k, v in test_dict.items():
      test_sents.extend(v)
    
    print("test_sents len= ", len(test_sents))
    
    train_feats = []
    train_labels = []

    print('Started preparing the features',datetime.datetime.now())
    for sent in train_sents:
        for i in range(len(sent)):
            feats = word2features(sent,i)
            train_feats.append(feats)
            train_labels.append(sent[i][1])

    vectorizer = DictVectorizer()
    X_train = vectorizer.fit_transform(train_feats)
    print('Finished preparing the features',datetime.datetime.now())

    print('Training the model')
    model = LinearSVC()
    
    model.fit(X_train, train_labels)
    print ('Trained the model')

    y_train_pred = model.predict(X_train)

    train_pathRead = "./train/system/"
    train_pathOut = "./train/system/"

    #create an .ann format for predictions
    createAnnFormat(train_dict, y_train_pred,train_pathRead, train_pathOut)
         
    #Dev Data
    dev_feats = []
    dev_labels = []

    for sent in dev_sents:
        for i in range(len(sent)):
            feats = word2features(sent,i)
            dev_feats.append(feats)
            dev_labels.append(sent[i][1])

    X_dev = vectorizer.transform(dev_feats)
    y_dev_pred = model.predict(X_dev)
        
    dev_pathRead = "./dev/system/"
    dev_pathOut = "./dev/system/"
    
    #create an .ann format for predictions
    createAnnFormat(dev_dict, y_dev_pred,dev_pathRead, dev_pathOut)

    #Test Data
    test_feats = []
    test_labels = []

    # switch to test_sents for your final results
    for sent in test_sents:
        for i in range(len(sent)):
            feats = word2features(sent,i)
            test_feats.append(feats)
            test_labels.append(sent[i][1])

    X_test = vectorizer.transform(test_feats)
    y_test_pred = model.predict(X_test)
        
    test_pathRead = "./test/system/"
    test_pathOut = "./test/system/"
    
    #create an .ann format for predictions
    createAnnFormat(test_dict, y_test_pred,test_pathRead, test_pathOut)