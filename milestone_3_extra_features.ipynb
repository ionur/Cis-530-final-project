{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "milestone-3-extra-features.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "z3R7nQYPkGsz",
        "colab_type": "code",
        "outputId": "4df090a1-c35c-4c80-bd16-6dc165531d81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "cell_type": "code",
      "source": [
        "# Mount your google drive. \n",
        "# Use this to save your PyTorch model for submission\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!mkdir /content/gdrive/Team\\ Drives/cis530\n",
        "#Test drive access. \n",
        "#You should have a test.txt in your Google drive\n",
        "with open('/content/gdrive/Team Drives/cis530/test.txt', 'w') as f:\n",
        "  f.write('This is a test file!')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "mkdir: cannot create directory ‘/content/gdrive/Team Drives/cis530’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sIaKrm1bQdHl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from nltk.corpus import conll2002\n",
        "from nltk.corpus import cess_esp as cess\n",
        "\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import PassiveAggressiveClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l8OT91hjTc_a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def isApostrophePresent(word):\n",
        "    if \"'\" in word:\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "  \n",
        "def isDashPresent(word):\n",
        "    if \"-\" in word:\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "def numDigits(word):\n",
        "    num = 0\n",
        "    for l in word:\n",
        "      if l.isdigit():\n",
        "        num +=1\n",
        "    \n",
        "    return num\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kFRisyy4Tdno",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def getfeats(word, postag, o, no_of_features = None):\n",
        "    \"\"\" This takes the word in question and\n",
        "    the offset with respect to the instance\n",
        "    word \"\"\"\n",
        "    o = str(o)\n",
        "    \n",
        "    features = [\n",
        "        \n",
        "        (o + 'word', word),\n",
        "         # TODO: add more features here.\n",
        "         (o + 'word.isupper', any(letter.isupper() for letter in word)),\n",
        "         (o + 'word.len', len(word) ),\n",
        "         (o + 'word.isdigit', any(letter.isdigit() for letter in word)),\n",
        "         (o + 'isApostrophePresent', isApostrophePresent(word)),\n",
        "         (o + 'isDashPresent', isDashPresent(word)),\n",
        "         (o + 'numDigits', numDigits(word))\n",
        "        \n",
        "    ]\n",
        "    return features\n",
        "  \n",
        "    \n",
        "    if( no_of_features != None ):\n",
        "      return features\n",
        "    else:\n",
        "      return features[:no_of_features]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XWE_ZtfUTgQJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def word2features(sent, i , no_of_features = None):\n",
        "    \"\"\" The function generates all features\n",
        "    for the word at position i in the\n",
        "    sentence.\"\"\"\n",
        "    features = []\n",
        "    # the window around the token\n",
        "    featlist = [('bias', 1.0)]\n",
        "    features.extend(featlist)\n",
        "\n",
        "    for o in [-1,0,2]:\n",
        "        if i+o >= 0 and i+o < len(sent):\n",
        "            word = sent[i+o][0]\n",
        "#             postag = sent[i+o][1]\n",
        "            postag = \"unknown\"\n",
        "            featlist = getfeats(word, postag, o, no_of_features)\n",
        "            features.extend(featlist)\n",
        "        elif i+o<0:\n",
        "            featlist = [('BOS', 1)]\n",
        "            features.extend(featlist)\n",
        "        else:\n",
        "            featlist = [('EOS', 1)]\n",
        "            features.extend(featlist)    \n",
        "    return dict(features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c88IAh_K9xI-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def runClassifier(model,no_of_features):\n",
        "    #Gathers the data\n",
        "\n",
        "    #Reports the performance of train/dev/test\n",
        "    train_feats = []\n",
        "    train_labels = []\n",
        "\n",
        "    for sent in train_sents:\n",
        "        for i in range(len(sent)):\n",
        "            feats = word2features(sent,i,no_of_features)\n",
        "            \n",
        "            train_feats.append(feats)\n",
        "            train_labels.append(sent[i][-1])\n",
        "\n",
        "    vectorizer = DictVectorizer()\n",
        "    X_train = vectorizer.fit_transform(train_feats)\n",
        "\n",
        "        \n",
        "    #Fit the data to the model\n",
        "    model.fit(X_train, train_labels)\n",
        "\n",
        "\n",
        "    #Training Data\n",
        "    y_train_pred = model.predict(X_train)\n",
        "\n",
        "    j = 0\n",
        "    print(\"Writing to train_results.txt\")\n",
        "    # format is: word gold pred\n",
        "    with open(\"/content/gdrive/Team Drives/cis530/results/train_results.txt\", \"w\") as out:\n",
        "        for sent in train_sents: \n",
        "            for i in range(len(sent)):\n",
        "                word = sent[i][0]\n",
        "                gold = sent[i][-1]\n",
        "                pred = y_train_pred[j]\n",
        "                j += 1\n",
        "                out.write(\"{}\\t{}\\t{}\\n\".format(word,gold,pred))\n",
        "        out.write(\"\\n\")\n",
        "\n",
        "    #Dev Data\n",
        "    dev_feats = []\n",
        "    dev_labels = []\n",
        "\n",
        "    # switch to test_sents for your final results\n",
        "    for sent in dev_sents:\n",
        "        for i in range(len(sent)):\n",
        "            feats = word2features(sent,i)\n",
        "            dev_feats.append(feats)\n",
        "            dev_labels.append(sent[i][-1])\n",
        "\n",
        "    X_dev = vectorizer.transform(dev_feats)\n",
        "    y_dev_pred = model.predict(X_dev)\n",
        "\n",
        "    j = 0\n",
        "    print(\"Writing to dev_results.txt\")\n",
        "    # format is: word gold pred\n",
        "    with open(\"/content/gdrive/Team Drives/cis530/results/dev_results.txt\", \"w\") as out:\n",
        "        for sent in dev_sents: \n",
        "            for i in range(len(sent)):\n",
        "                word = sent[i][0]\n",
        "                gold = sent[i][-1]\n",
        "                pred = y_dev_pred[j]\n",
        "                j += 1\n",
        "                out.write(\"{}\\t{}\\t{}\\n\".format(word,gold,pred))\n",
        "        out.write(\"\\n\")\n",
        "\n",
        "    #Test Data\n",
        "    test_feats = []\n",
        "    test_labels = []\n",
        "\n",
        "    # switch to test_sents for your final results\n",
        "    for sent in test_sents:\n",
        "        for i in range(len(sent)):\n",
        "            feats = word2features(sent,i)\n",
        "            test_feats.append(feats)\n",
        "            test_labels.append(sent[i][-1])\n",
        "\n",
        "    X_test = vectorizer.transform(test_feats)\n",
        "    y_test_pred = model.predict(X_test)\n",
        "\n",
        "    j = 0\n",
        "    print(\"Writing to test_results.txt\")\n",
        "    # format is: word gold pred\n",
        "    with open(\"/content/gdrive/Team Drives/cis530/results/test_results.txt\", \"w\") as out:\n",
        "        for sent in test_sents: \n",
        "            for i in range(len(sent)):\n",
        "                word = sent[i][0]\n",
        "                gold = sent[i][-1]\n",
        "                pred = y_test_pred[j]\n",
        "                j += 1\n",
        "                out.write(\"{}\\t{}\\t{}\\n\".format(word,gold,pred))\n",
        "        out.write(\"\\n\")\n",
        "        \n",
        "        \n",
        "    #Evaluate training results\n",
        "    print('Train Results for the model',model,' with ',no_of_features,' of features')\n",
        "    \n",
        "    with open('/content/gdrive/Team Drives/cis530/results/train_results.txt') as f:\n",
        "      counts = evaluate(f)\n",
        "    report(counts)\n",
        "    \n",
        "    #Evaluate Dev results\n",
        "    print('Dev Results for the model',model,' with ',no_of_features,' of features')\n",
        "    \n",
        "    with open('/content/gdrive/Team Drives/cis530/results/dev_results.txt') as f:\n",
        "      counts = evaluate(f)\n",
        "    report(counts)\n",
        "    \n",
        "    #Evaluate test results\n",
        "    print('Test Results for the model',model,' with ',no_of_features,' of features')\n",
        "    \n",
        "    with open('/content/gdrive/Team Drives/cis530/results/test_results.txt') as f:\n",
        "      counts = evaluate(f)\n",
        "    report(counts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HIyr1WKDTidh",
        "colab_type": "code",
        "outputId": "75a0dc93-3c10-49b5-8e90-4314c6275d87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4437
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "if __name__ == \"__main__\":\n",
        "  \n",
        "    # Load the training data\n",
        "    file = open('/content/gdrive/Team Drives/cis530/ner_tagged_sentences/train_ner_tagged_sentences.pickle','rb')\n",
        "    train_sents = pickle.load(file)\n",
        "    print(\"train_sents len= \", len(train_sents))\n",
        "      \n",
        "    file = open('/content/gdrive/Team Drives/cis530/ner_tagged_sentences/dev_ner_tagged_sentences.pickle','rb')\n",
        "    dev_sents = pickle.load(file)\n",
        "    file.close()\n",
        "    \n",
        "    print(\"dev_sents len= \", len(dev_sents))\n",
        "      \n",
        "    file = open('/content/gdrive/Team Drives/cis530/ner_tagged_sentences/test_ner_tagged_sentences.pickle','rb')\n",
        "    test_sents = pickle.load(file)\n",
        "    file.close()\n",
        "    \n",
        "    print(\"test_sents len= \", len(test_sents))\n",
        "    \n",
        "    no_of_features = 7\n",
        "    models = [LinearSVC(),LinearSVC(C=0.01),LinearSVC(C=10),GaussianNB(),MultinomialNB(),DecisionTreeClassifier()]\n",
        "    \n",
        "    for model in models:\n",
        "      for i in range(1,no_of_features+1,1):\n",
        "        runClassifier(model,i)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_sents len=  8300\n",
            "dev_sents len=  4048\n",
            "test_sents len=  3231\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Writing to train_results.txt\n",
            "Writing to dev_results.txt\n",
            "Writing to test_results.txt\n",
            "Train Results for the model LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
            "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
            "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
            "     verbose=0)  with  1  of features\n",
            "processed 157843 tokens with 8675 phrases; found: 9108 phrases; correct: 8347.\n",
            "accuracy:  99.56%; precision:  91.64%; recall:  96.22%; FB1:  93.88\n",
            "            CALLE: precision:  63.02%; recall:  82.87%; FB1:  71.60  860\n",
            "     CENTRO_SALUD: precision: 100.00%; recall: 100.00%; FB1: 100.00  4\n",
            "CORREO_ELECTRONICO: precision:  91.08%; recall:  98.83%; FB1:  94.80  370\n",
            "EDAD_SUJETO_ASISTENCIA: precision:  87.28%; recall:  92.46%; FB1:  89.80  857\n",
            "FAMILIARES_SUJETO_ASISTENCIA: precision:  84.94%; recall:  81.50%; FB1:  83.19  166\n",
            "           FECHAS: precision:  99.19%; recall:  99.19%; FB1:  99.19  987\n",
            "         HOSPITAL: precision:  72.97%; recall:  87.57%; FB1:  79.61  222\n",
            " ID_ASEGURAMIENTO: precision:  98.25%; recall:  98.60%; FB1:  98.42  286\n",
            "ID_CONTACTO_ASISTENCIAL: precision: 100.00%; recall:  98.08%; FB1:  99.03  51\n",
            "ID_SUJETO_ASISTENCIA: precision:  97.42%; recall:  98.11%; FB1:  97.77  427\n",
            "ID_TITULACION_PERSONAL_SANITARIO: precision:  98.60%; recall:  99.43%; FB1:  99.01  356\n",
            "      INSTITUCION: precision:  64.20%; recall:  78.79%; FB1:  70.75  81\n",
            "NOMBRE_PERSONAL_SANITARIO: precision:  96.75%; recall:  98.72%; FB1:  97.72  799\n",
            "NOMBRE_SUJETO_ASISTENCIA: precision:  98.16%; recall:  98.89%; FB1:  98.53  817\n",
            "       NUMERO_FAX: precision:  85.71%; recall:  85.71%; FB1:  85.71  7\n",
            "  NUMERO_TELEFONO: precision:  95.65%; recall: 100.00%; FB1:  97.78  46\n",
            "OTROS_SUJETO_ASISTENCIA: precision:  44.44%; recall:  57.14%; FB1:  50.00  9\n",
            "             PAIS: precision:  96.44%; recall:  99.45%; FB1:  97.92  562\n",
            "        PROFESION: precision:  85.71%; recall:  90.00%; FB1:  87.80  21\n",
            "SEXO_SUJETO_ASISTENCIA: precision:  97.56%; recall:  99.86%; FB1:  98.70  737\n",
            "       TERRITORIO: precision:  95.29%; recall:  97.86%; FB1:  96.56  1443\n",
            "Dev Results for the model LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
            "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
            "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
            "     verbose=0)  with  1  of features\n",
            "processed 74003 tokens with 4332 phrases; found: 4859 phrases; correct: 3342.\n",
            "accuracy:  97.42%; precision:  68.78%; recall:  77.15%; FB1:  72.72\n",
            "            CALLE: precision:  14.49%; recall:  32.29%; FB1:  20.00  711\n",
            "     CENTRO_SALUD: precision:   0.00%; recall:   0.00%; FB1:   0.00  8\n",
            "CORREO_ELECTRONICO: precision:  73.22%; recall:  74.44%; FB1:  73.83  183\n",
            "EDAD_SUJETO_ASISTENCIA: precision:  76.19%; recall:  82.47%; FB1:  79.21  420\n",
            "FAMILIARES_SUJETO_ASISTENCIA: precision:  73.13%; recall:  67.12%; FB1:  70.00  67\n",
            "           FECHAS: precision:  85.84%; recall:  88.08%; FB1:  86.95  551\n",
            "         HOSPITAL: precision:  34.56%; recall:  47.47%; FB1:  40.00  136\n",
            " ID_ASEGURAMIENTO: precision:  84.93%; recall:  93.23%; FB1:  88.89  146\n",
            "ID_CONTACTO_ASISTENCIAL: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\n",
            "ID_EMPLEO_PERSONAL_SANITARIO: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\n",
            "ID_SUJETO_ASISTENCIA: precision:  63.03%; recall:  84.83%; FB1:  72.32  284\n",
            "ID_TITULACION_PERSONAL_SANITARIO: precision:  89.56%; recall:  97.60%; FB1:  93.41  182\n",
            "      INSTITUCION: precision:  12.50%; recall:  11.86%; FB1:  12.17  56\n",
            "NOMBRE_PERSONAL_SANITARIO: precision:  63.58%; recall:  79.27%; FB1:  70.56  475\n",
            "NOMBRE_SUJETO_ASISTENCIA: precision:  80.93%; recall:  94.32%; FB1:  87.11  451\n",
            "       NUMERO_FAX: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\n",
            "  NUMERO_TELEFONO: precision:  52.38%; recall:  50.00%; FB1:  51.16  21\n",
            "OTROS_SUJETO_ASISTENCIA: precision:   0.00%; recall:   0.00%; FB1:   0.00  4\n",
            "             PAIS: precision:  96.98%; recall:  96.62%; FB1:  96.80  265\n",
            "        PROFESION: precision:  25.00%; recall:  25.00%; FB1:  25.00  4\n",
            "SEXO_SUJETO_ASISTENCIA: precision:  94.41%; recall:  98.54%; FB1:  96.43  358\n",
            "       TERRITORIO: precision:  87.34%; recall:  63.98%; FB1:  73.86  537\n",
            "Test Results for the model LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
            "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
            "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
            "     verbose=0)  with  1  of features\n",
            "processed 66137 tokens with 3522 phrases; found: 4011 phrases; correct: 2757.\n",
            "accuracy:  97.64%; precision:  68.74%; recall:  78.28%; FB1:  73.20\n",
            "            CALLE: precision:  18.20%; recall:  39.03%; FB1:  24.82  577\n",
            "     CENTRO_SALUD: precision:   0.00%; recall:   0.00%; FB1:   0.00  6\n",
            "CORREO_ELECTRONICO: precision:  74.67%; recall:  82.35%; FB1:  78.32  150\n",
            "EDAD_SUJETO_ASISTENCIA: precision:  77.21%; recall:  83.38%; FB1:  80.18  351\n",
            "FAMILIARES_SUJETO_ASISTENCIA: precision:  61.84%; recall:  54.65%; FB1:  58.02  76\n",
            "           FECHAS: precision:  87.70%; recall:  97.93%; FB1:  92.53  431\n",
            "         HOSPITAL: precision:  31.06%; recall:  44.57%; FB1:  36.61  132\n",
            " ID_ASEGURAMIENTO: precision:  95.42%; recall:  97.66%; FB1:  96.53  131\n",
            "ID_CONTACTO_ASISTENCIAL: precision:   0.00%; recall:   0.00%; FB1:   0.00  1\n",
            "ID_SUJETO_ASISTENCIA: precision:  59.66%; recall:  87.12%; FB1:  70.82  238\n",
            "ID_TITULACION_PERSONAL_SANITARIO: precision:  93.79%; recall:  99.27%; FB1:  96.45  145\n",
            "      INSTITUCION: precision:   0.00%; recall:   0.00%; FB1:   0.00  25\n",
            "NOMBRE_PERSONAL_SANITARIO: precision:  59.84%; recall:  73.53%; FB1:  65.98  376\n",
            "NOMBRE_SUJETO_ASISTENCIA: precision:  74.05%; recall:  92.68%; FB1:  82.32  393\n",
            "       NUMERO_FAX: precision:   0.00%; recall:   0.00%; FB1:   0.00  1\n",
            "  NUMERO_TELEFONO: precision:  36.36%; recall:  33.33%; FB1:  34.78  11\n",
            "OTROS_SUJETO_ASISTENCIA: precision:   0.00%; recall:   0.00%; FB1:   0.00  1\n",
            "             PAIS: precision:  95.89%; recall:  95.45%; FB1:  95.67  219\n",
            "        PROFESION: precision:  20.00%; recall:  25.00%; FB1:  22.22  5\n",
            "SEXO_SUJETO_ASISTENCIA: precision:  94.65%; recall: 100.00%; FB1:  97.25  299\n",
            "       TERRITORIO: precision:  87.13%; recall:  65.53%; FB1:  74.81  443\n",
            "Writing to train_results.txt\n",
            "Writing to dev_results.txt\n",
            "Writing to test_results.txt\n",
            "Train Results for the model LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
            "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
            "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
            "     verbose=0)  with  2  of features\n",
            "processed 157843 tokens with 8675 phrases; found: 9108 phrases; correct: 8346.\n",
            "accuracy:  99.56%; precision:  91.63%; recall:  96.21%; FB1:  93.86\n",
            "            CALLE: precision:  63.02%; recall:  82.87%; FB1:  71.60  860\n",
            "     CENTRO_SALUD: precision: 100.00%; recall: 100.00%; FB1: 100.00  4\n",
            "CORREO_ELECTRONICO: precision:  91.08%; recall:  98.83%; FB1:  94.80  370\n",
            "EDAD_SUJETO_ASISTENCIA: precision:  87.16%; recall:  92.34%; FB1:  89.68  857\n",
            "FAMILIARES_SUJETO_ASISTENCIA: precision:  84.94%; recall:  81.50%; FB1:  83.19  166\n",
            "           FECHAS: precision:  99.19%; recall:  99.19%; FB1:  99.19  987\n",
            "         HOSPITAL: precision:  72.97%; recall:  87.57%; FB1:  79.61  222\n",
            " ID_ASEGURAMIENTO: precision:  98.25%; recall:  98.60%; FB1:  98.42  286\n",
            "ID_CONTACTO_ASISTENCIAL: precision: 100.00%; recall:  98.08%; FB1:  99.03  51\n",
            "ID_SUJETO_ASISTENCIA: precision:  97.42%; recall:  98.11%; FB1:  97.77  427\n",
            "ID_TITULACION_PERSONAL_SANITARIO: precision:  98.60%; recall:  99.43%; FB1:  99.01  356\n",
            "      INSTITUCION: precision:  64.20%; recall:  78.79%; FB1:  70.75  81\n",
            "NOMBRE_PERSONAL_SANITARIO: precision:  96.75%; recall:  98.72%; FB1:  97.72  799\n",
            "NOMBRE_SUJETO_ASISTENCIA: precision:  98.16%; recall:  98.89%; FB1:  98.53  817\n",
            "       NUMERO_FAX: precision:  85.71%; recall:  85.71%; FB1:  85.71  7\n",
            "  NUMERO_TELEFONO: precision:  95.65%; recall: 100.00%; FB1:  97.78  46\n",
            "OTROS_SUJETO_ASISTENCIA: precision:  44.44%; recall:  57.14%; FB1:  50.00  9\n",
            "             PAIS: precision:  96.44%; recall:  99.45%; FB1:  97.92  562\n",
            "        PROFESION: precision:  85.71%; recall:  90.00%; FB1:  87.80  21\n",
            "SEXO_SUJETO_ASISTENCIA: precision:  97.56%; recall:  99.86%; FB1:  98.70  737\n",
            "       TERRITORIO: precision:  95.29%; recall:  97.86%; FB1:  96.56  1443\n",
            "Dev Results for the model LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
            "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
            "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
            "     verbose=0)  with  2  of features\n",
            "processed 74003 tokens with 4332 phrases; found: 4865 phrases; correct: 3342.\n",
            "accuracy:  97.42%; precision:  68.69%; recall:  77.15%; FB1:  72.68\n",
            "            CALLE: precision:  14.45%; recall:  32.29%; FB1:  19.96  713\n",
            "     CENTRO_SALUD: precision:   0.00%; recall:   0.00%; FB1:   0.00  8\n",
            "CORREO_ELECTRONICO: precision:  73.22%; recall:  74.44%; FB1:  73.83  183\n",
            "EDAD_SUJETO_ASISTENCIA: precision:  76.19%; recall:  82.47%; FB1:  79.21  420\n",
            "FAMILIARES_SUJETO_ASISTENCIA: precision:  73.13%; recall:  67.12%; FB1:  70.00  67\n",
            "           FECHAS: precision:  85.84%; recall:  88.08%; FB1:  86.95  551\n",
            "         HOSPITAL: precision:  34.56%; recall:  47.47%; FB1:  40.00  136\n",
            " ID_ASEGURAMIENTO: precision:  84.93%; recall:  93.23%; FB1:  88.89  146\n",
            "ID_CONTACTO_ASISTENCIAL: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\n",
            "ID_EMPLEO_PERSONAL_SANITARIO: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\n",
            "ID_SUJETO_ASISTENCIA: precision:  63.03%; recall:  84.83%; FB1:  72.32  284\n",
            "ID_TITULACION_PERSONAL_SANITARIO: precision:  88.59%; recall:  97.60%; FB1:  92.88  184\n",
            "      INSTITUCION: precision:  12.50%; recall:  11.86%; FB1:  12.17  56\n",
            "NOMBRE_PERSONAL_SANITARIO: precision:  63.58%; recall:  79.27%; FB1:  70.56  475\n",
            "NOMBRE_SUJETO_ASISTENCIA: precision:  80.93%; recall:  94.32%; FB1:  87.11  451\n",
            "       NUMERO_FAX: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\n",
            "  NUMERO_TELEFONO: precision:  47.83%; recall:  50.00%; FB1:  48.89  23\n",
            "OTROS_SUJETO_ASISTENCIA: precision:   0.00%; recall:   0.00%; FB1:   0.00  4\n",
            "             PAIS: precision:  96.98%; recall:  96.62%; FB1:  96.80  265\n",
            "        PROFESION: precision:  25.00%; recall:  25.00%; FB1:  25.00  4\n",
            "SEXO_SUJETO_ASISTENCIA: precision:  94.41%; recall:  98.54%; FB1:  96.43  358\n",
            "       TERRITORIO: precision:  87.34%; recall:  63.98%; FB1:  73.86  537\n",
            "Test Results for the model LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
            "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
            "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
            "     verbose=0)  with  2  of features\n",
            "processed 66137 tokens with 3522 phrases; found: 4013 phrases; correct: 2757.\n",
            "accuracy:  97.64%; precision:  68.70%; recall:  78.28%; FB1:  73.18\n",
            "            CALLE: precision:  18.17%; recall:  39.03%; FB1:  24.79  578\n",
            "     CENTRO_SALUD: precision:   0.00%; recall:   0.00%; FB1:   0.00  6\n",
            "CORREO_ELECTRONICO: precision:  74.67%; recall:  82.35%; FB1:  78.32  150\n",
            "EDAD_SUJETO_ASISTENCIA: precision:  77.21%; recall:  83.38%; FB1:  80.18  351\n",
            "FAMILIARES_SUJETO_ASISTENCIA: precision:  61.84%; recall:  54.65%; FB1:  58.02  76\n",
            "           FECHAS: precision:  87.70%; recall:  97.93%; FB1:  92.53  431\n",
            "         HOSPITAL: precision:  31.06%; recall:  44.57%; FB1:  36.61  132\n",
            " ID_ASEGURAMIENTO: precision:  95.42%; recall:  97.66%; FB1:  96.53  131\n",
            "ID_CONTACTO_ASISTENCIAL: precision:   0.00%; recall:   0.00%; FB1:   0.00  1\n",
            "ID_SUJETO_ASISTENCIA: precision:  59.66%; recall:  87.12%; FB1:  70.82  238\n",
            "ID_TITULACION_PERSONAL_SANITARIO: precision:  93.79%; recall:  99.27%; FB1:  96.45  145\n",
            "      INSTITUCION: precision:   0.00%; recall:   0.00%; FB1:   0.00  25\n",
            "NOMBRE_PERSONAL_SANITARIO: precision:  59.52%; recall:  73.53%; FB1:  65.79  378\n",
            "NOMBRE_SUJETO_ASISTENCIA: precision:  74.05%; recall:  92.68%; FB1:  82.32  393\n",
            "       NUMERO_FAX: precision:   0.00%; recall:   0.00%; FB1:   0.00  1\n",
            "  NUMERO_TELEFONO: precision:  36.36%; recall:  33.33%; FB1:  34.78  11\n",
            "OTROS_SUJETO_ASISTENCIA: precision:   0.00%; recall:   0.00%; FB1:   0.00  1\n",
            "             PAIS: precision:  95.89%; recall:  95.45%; FB1:  95.67  219\n",
            "        PROFESION: precision:  20.00%; recall:  25.00%; FB1:  22.22  5\n",
            "SEXO_SUJETO_ASISTENCIA: precision:  94.65%; recall: 100.00%; FB1:  97.25  299\n",
            "       TERRITORIO: precision:  87.33%; recall:  65.53%; FB1:  74.88  442\n",
            "Writing to train_results.txt\n",
            "Writing to dev_results.txt\n",
            "Writing to test_results.txt\n",
            "Train Results for the model LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
            "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
            "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
            "     verbose=0)  with  3  of features\n",
            "processed 157843 tokens with 8675 phrases; found: 9116 phrases; correct: 8350.\n",
            "accuracy:  99.56%; precision:  91.60%; recall:  96.25%; FB1:  93.87\n",
            "            CALLE: precision:  62.77%; recall:  83.03%; FB1:  71.49  865\n",
            "     CENTRO_SALUD: precision: 100.00%; recall: 100.00%; FB1: 100.00  4\n",
            "CORREO_ELECTRONICO: precision:  91.08%; recall:  98.83%; FB1:  94.80  370\n",
            "EDAD_SUJETO_ASISTENCIA: precision:  87.18%; recall:  92.46%; FB1:  89.74  858\n",
            "FAMILIARES_SUJETO_ASISTENCIA: precision:  84.43%; recall:  81.50%; FB1:  82.94  167\n",
            "           FECHAS: precision:  99.29%; recall:  99.29%; FB1:  99.29  987\n",
            "         HOSPITAL: precision:  72.97%; recall:  87.57%; FB1:  79.61  222\n",
            " ID_ASEGURAMIENTO: precision:  98.25%; recall:  98.60%; FB1:  98.42  286\n",
            "ID_CONTACTO_ASISTENCIAL: precision: 100.00%; recall:  98.08%; FB1:  99.03  51\n",
            "ID_SUJETO_ASISTENCIA: precision:  97.42%; recall:  98.11%; FB1:  97.77  427\n",
            "ID_TITULACION_PERSONAL_SANITARIO: precision:  98.32%; recall:  99.43%; FB1:  98.87  357\n",
            "      INSTITUCION: precision:  64.20%; recall:  78.79%; FB1:  70.75  81\n",
            "NOMBRE_PERSONAL_SANITARIO: precision:  96.87%; recall:  98.85%; FB1:  97.85  799\n",
            "NOMBRE_SUJETO_ASISTENCIA: precision:  98.16%; recall:  98.89%; FB1:  98.53  817\n",
            "       NUMERO_FAX: precision:  85.71%; recall:  85.71%; FB1:  85.71  7\n",
            "  NUMERO_TELEFONO: precision:  95.65%; recall: 100.00%; FB1:  97.78  46\n",
            "OTROS_SUJETO_ASISTENCIA: precision:  44.44%; recall:  57.14%; FB1:  50.00  9\n",
            "             PAIS: precision:  96.44%; recall:  99.45%; FB1:  97.92  562\n",
            "        PROFESION: precision:  85.71%; recall:  90.00%; FB1:  87.80  21\n",
            "SEXO_SUJETO_ASISTENCIA: precision:  97.56%; recall:  99.86%; FB1:  98.70  737\n",
            "       TERRITORIO: precision:  95.29%; recall:  97.86%; FB1:  96.56  1443\n",
            "Dev Results for the model LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
            "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
            "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
            "     verbose=0)  with  3  of features\n",
            "processed 74003 tokens with 4332 phrases; found: 4882 phrases; correct: 3349.\n",
            "accuracy:  97.42%; precision:  68.60%; recall:  77.31%; FB1:  72.69\n",
            "            CALLE: precision:  14.39%; recall:  32.29%; FB1:  19.90  716\n",
            "     CENTRO_SALUD: precision:   0.00%; recall:   0.00%; FB1:   0.00  8\n",
            "CORREO_ELECTRONICO: precision:  74.32%; recall:  75.56%; FB1:  74.93  183\n",
            "EDAD_SUJETO_ASISTENCIA: precision:  75.89%; recall:  82.73%; FB1:  79.16  423\n",
            "FAMILIARES_SUJETO_ASISTENCIA: precision:  73.13%; recall:  67.12%; FB1:  70.00  67\n",
            "           FECHAS: precision:  85.84%; recall:  88.08%; FB1:  86.95  551\n",
            "         HOSPITAL: precision:  33.82%; recall:  46.46%; FB1:  39.15  136\n",
            " ID_ASEGURAMIENTO: precision:  84.93%; recall:  93.23%; FB1:  88.89  146\n",
            "ID_CONTACTO_ASISTENCIAL: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\n",
            "ID_EMPLEO_PERSONAL_SANITARIO: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\n",
            "ID_SUJETO_ASISTENCIA: precision:  63.03%; recall:  84.83%; FB1:  72.32  284\n",
            "ID_TITULACION_PERSONAL_SANITARIO: precision:  86.70%; recall:  97.60%; FB1:  91.83  188\n",
            "      INSTITUCION: precision:  12.28%; recall:  11.86%; FB1:  12.07  57\n",
            "NOMBRE_PERSONAL_SANITARIO: precision:  63.81%; recall:  80.05%; FB1:  71.01  478\n",
            "NOMBRE_SUJETO_ASISTENCIA: precision:  80.93%; recall:  94.32%; FB1:  87.11  451\n",
            "       NUMERO_FAX: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\n",
            "  NUMERO_TELEFONO: precision:  45.83%; recall:  50.00%; FB1:  47.83  24\n",
            "OTROS_SUJETO_ASISTENCIA: precision:   0.00%; recall:   0.00%; FB1:   0.00  4\n",
            "             PAIS: precision:  96.98%; recall:  96.62%; FB1:  96.80  265\n",
            "        PROFESION: precision:  25.00%; recall:  25.00%; FB1:  25.00  4\n",
            "SEXO_SUJETO_ASISTENCIA: precision:  94.41%; recall:  98.54%; FB1:  96.43  358\n",
            "       TERRITORIO: precision:  87.38%; recall:  64.26%; FB1:  74.06  539\n",
            "Test Results for the model LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
            "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
            "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
            "     verbose=0)  with  3  of features\n",
            "processed 66137 tokens with 3522 phrases; found: 4035 phrases; correct: 2765.\n",
            "accuracy:  97.64%; precision:  68.53%; recall:  78.51%; FB1:  73.18\n",
            "            CALLE: precision:  17.95%; recall:  39.03%; FB1:  24.59  585\n",
            "     CENTRO_SALUD: precision:   0.00%; recall:   0.00%; FB1:   0.00  6\n",
            "CORREO_ELECTRONICO: precision:  76.00%; recall:  83.82%; FB1:  79.72  150\n",
            "EDAD_SUJETO_ASISTENCIA: precision:  77.12%; recall:  84.00%; FB1:  80.41  354\n",
            "FAMILIARES_SUJETO_ASISTENCIA: precision:  61.84%; recall:  54.65%; FB1:  58.02  76\n",
            "           FECHAS: precision:  87.50%; recall:  97.93%; FB1:  92.42  432\n",
            "         HOSPITAL: precision:  30.60%; recall:  44.57%; FB1:  36.28  134\n",
            " ID_ASEGURAMIENTO: precision:  95.42%; recall:  97.66%; FB1:  96.53  131\n",
            "ID_CONTACTO_ASISTENCIAL: precision:   0.00%; recall:   0.00%; FB1:   0.00  1\n",
            "ID_SUJETO_ASISTENCIA: precision:  59.41%; recall:  87.12%; FB1:  70.65  239\n",
            "ID_TITULACION_PERSONAL_SANITARIO: precision:  93.79%; recall:  99.27%; FB1:  96.45  145\n",
            "      INSTITUCION: precision:   0.00%; recall:   0.00%; FB1:   0.00  26\n",
            "NOMBRE_PERSONAL_SANITARIO: precision:  59.95%; recall:  74.84%; FB1:  66.57  382\n",
            "NOMBRE_SUJETO_ASISTENCIA: precision:  74.05%; recall:  92.68%; FB1:  82.32  393\n",
            "       NUMERO_FAX: precision:   0.00%; recall:   0.00%; FB1:   0.00  1\n",
            "  NUMERO_TELEFONO: precision:  33.33%; recall:  33.33%; FB1:  33.33  12\n",
            "OTROS_SUJETO_ASISTENCIA: precision:   0.00%; recall:   0.00%; FB1:   0.00  1\n",
            "             PAIS: precision:  95.89%; recall:  95.45%; FB1:  95.67  219\n",
            "        PROFESION: precision:  20.00%; recall:  25.00%; FB1:  22.22  5\n",
            "SEXO_SUJETO_ASISTENCIA: precision:  94.65%; recall: 100.00%; FB1:  97.25  299\n",
            "       TERRITORIO: precision:  86.94%; recall:  65.53%; FB1:  74.73  444\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UyThNPeCr5y-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Evaluation\n",
        "#!/usr/bin/env python\n",
        "\n",
        "# Python version of the evaluation script from CoNLL'00-\n",
        "\n",
        "# Intentional differences:\n",
        "# - accept any space as delimiter by default\n",
        "# - optional file argument (default STDIN)\n",
        "# - option to set boundary (-b argument)\n",
        "# - LaTeX output (-l argument) not supported\n",
        "# - raw tags (-r argument) not supported\n",
        "\n",
        "import sys\n",
        "import re\n",
        "\n",
        "from collections import defaultdict, namedtuple\n",
        "\n",
        "ANY_SPACE = '<SPACE>'\n",
        "\n",
        "class FormatError(Exception):\n",
        "    pass\n",
        "\n",
        "Metrics = namedtuple('Metrics', 'tp fp fn prec rec fscore')\n",
        "\n",
        "class EvalCounts(object):\n",
        "    def __init__(self):\n",
        "        self.correct_chunk = 0    # number of correctly identified chunks\n",
        "        self.correct_tags = 0     # number of correct chunk tags\n",
        "        self.found_correct = 0    # number of chunks in corpus\n",
        "        self.found_guessed = 0    # number of identified chunks\n",
        "        self.token_counter = 0    # token counter (ignores sentence breaks)\n",
        "\n",
        "        # counts by type\n",
        "        self.t_correct_chunk = defaultdict(int)\n",
        "        self.t_found_correct = defaultdict(int)\n",
        "        self.t_found_guessed = defaultdict(int)\n",
        "\n",
        "def parse_args(argv):\n",
        "    import argparse\n",
        "    parser = argparse.ArgumentParser(\n",
        "        description='evaluate tagging results using CoNLL criteria',\n",
        "        formatter_class=argparse.ArgumentDefaultsHelpFormatter\n",
        "    )\n",
        "    arg = parser.add_argument\n",
        "    arg('-b', '--boundary', metavar='STR', default='-X-',\n",
        "        help='sentence boundary')\n",
        "    arg('-d', '--delimiter', metavar='CHAR', default=ANY_SPACE,\n",
        "        help='character delimiting items in input')\n",
        "    arg('-o', '--otag', metavar='CHAR', default='O',\n",
        "        help='alternative outside tag')\n",
        "    arg('file', nargs='?', default=None)\n",
        "    return parser.parse_args(argv)\n",
        "\n",
        "def parse_tag(t):\n",
        "    m = re.match(r'^([^-]*)-(.*)$', t)\n",
        "    return m.groups() if m else (t, '')\n",
        "\n",
        "def evaluate(iterable, options=None):\n",
        "    if options is None:\n",
        "        options = parse_args([])    # use defaults\n",
        "\n",
        "    counts = EvalCounts()\n",
        "    num_features = None       # number of features per line\n",
        "    in_correct = False        # currently processed chunks is correct until now\n",
        "    last_correct = 'O'        # previous chunk tag in corpus\n",
        "    last_correct_type = ''    # type of previously identified chunk tag\n",
        "    last_guessed = 'O'        # previously identified chunk tag\n",
        "    last_guessed_type = ''    # type of previous chunk tag in corpus\n",
        "\n",
        "    for line in iterable:\n",
        "        line = line.rstrip('\\r\\n')\n",
        "\n",
        "        if options.delimiter == ANY_SPACE:\n",
        "            features = line.split()\n",
        "        else:\n",
        "            features = line.split(options.delimiter)\n",
        "\n",
        "        if num_features is None:\n",
        "            num_features = len(features)\n",
        "        elif num_features != len(features) and len(features) != 0:\n",
        "            raise FormatError('unexpected number of features: %d (%d)' %\n",
        "                              (len(features), num_features))\n",
        "\n",
        "        if len(features) == 0 or features[0] == options.boundary:\n",
        "            features = [options.boundary, 'O', 'O']\n",
        "        if len(features) < 3:\n",
        "            raise FormatError('unexpected number of features in line %s' % line)\n",
        "\n",
        "        guessed, guessed_type = parse_tag(features.pop())\n",
        "        correct, correct_type = parse_tag(features.pop())\n",
        "        first_item = features.pop(0)\n",
        "\n",
        "        if first_item == options.boundary:\n",
        "            guessed = 'O'\n",
        "\n",
        "        end_correct = end_of_chunk(last_correct, correct,\n",
        "                                   last_correct_type, correct_type)\n",
        "        end_guessed = end_of_chunk(last_guessed, guessed,\n",
        "                                   last_guessed_type, guessed_type)\n",
        "        start_correct = start_of_chunk(last_correct, correct,\n",
        "                                       last_correct_type, correct_type)\n",
        "        start_guessed = start_of_chunk(last_guessed, guessed,\n",
        "                                       last_guessed_type, guessed_type)\n",
        "\n",
        "        if in_correct:\n",
        "            if (end_correct and end_guessed and\n",
        "                last_guessed_type == last_correct_type):\n",
        "                in_correct = False\n",
        "                counts.correct_chunk += 1\n",
        "                counts.t_correct_chunk[last_correct_type] += 1\n",
        "            elif (end_correct != end_guessed or guessed_type != correct_type):\n",
        "                in_correct = False\n",
        "\n",
        "        if start_correct and start_guessed and guessed_type == correct_type:\n",
        "            in_correct = True\n",
        "\n",
        "        if start_correct:\n",
        "            counts.found_correct += 1\n",
        "            counts.t_found_correct[correct_type] += 1\n",
        "        if start_guessed:\n",
        "            counts.found_guessed += 1\n",
        "            counts.t_found_guessed[guessed_type] += 1\n",
        "        if first_item != options.boundary:\n",
        "            if correct == guessed and guessed_type == correct_type:\n",
        "                counts.correct_tags += 1\n",
        "            counts.token_counter += 1\n",
        "\n",
        "        last_guessed = guessed\n",
        "        last_correct = correct\n",
        "        last_guessed_type = guessed_type\n",
        "        last_correct_type = correct_type\n",
        "\n",
        "    if in_correct:\n",
        "        counts.correct_chunk += 1\n",
        "        counts.t_correct_chunk[last_correct_type] += 1\n",
        "\n",
        "    return counts\n",
        "\n",
        "def uniq(iterable):\n",
        "  seen = set()\n",
        "  return [i for i in iterable if not (i in seen or seen.add(i))]\n",
        "\n",
        "def calculate_metrics(correct, guessed, total):\n",
        "    tp, fp, fn = correct, guessed-correct, total-correct\n",
        "    p = 0 if tp + fp == 0 else 1.*tp / (tp + fp)\n",
        "    r = 0 if tp + fn == 0 else 1.*tp / (tp + fn)\n",
        "    f = 0 if p + r == 0 else 2 * p * r / (p + r)\n",
        "    return Metrics(tp, fp, fn, p, r, f)\n",
        "\n",
        "def metrics(counts):\n",
        "    c = counts\n",
        "    overall = calculate_metrics(\n",
        "        c.correct_chunk, c.found_guessed, c.found_correct\n",
        "    )\n",
        "    by_type = {}\n",
        "    for t in uniq(list(c.t_found_correct) + list(c.t_found_guessed)):\n",
        "        by_type[t] = calculate_metrics(\n",
        "            c.t_correct_chunk[t], c.t_found_guessed[t], c.t_found_correct[t]\n",
        "        )\n",
        "    return overall, by_type\n",
        "\n",
        "def report(counts, out=None):\n",
        "    if out is None:\n",
        "        out = sys.stdout\n",
        "\n",
        "    overall, by_type = metrics(counts)\n",
        "\n",
        "    c = counts\n",
        "    out.write('processed %d tokens with %d phrases; ' %\n",
        "              (c.token_counter, c.found_correct))\n",
        "    out.write('found: %d phrases; correct: %d.\\n' %\n",
        "              (c.found_guessed, c.correct_chunk))\n",
        "\n",
        "    if c.token_counter > 0:\n",
        "        out.write('accuracy: %6.2f%%; ' %\n",
        "                  (100.*c.correct_tags/c.token_counter))\n",
        "        out.write('precision: %6.2f%%; ' % (100.*overall.prec))\n",
        "        out.write('recall: %6.2f%%; ' % (100.*overall.rec))\n",
        "        out.write('FB1: %6.2f\\n' % (100.*overall.fscore))\n",
        "\n",
        "    for i, m in sorted(by_type.items()):\n",
        "        out.write('%17s: ' % i)\n",
        "        out.write('precision: %6.2f%%; ' % (100.*m.prec))\n",
        "        out.write('recall: %6.2f%%; ' % (100.*m.rec))\n",
        "        out.write('FB1: %6.2f  %d\\n' % (100.*m.fscore, c.t_found_guessed[i]))\n",
        "\n",
        "def end_of_chunk(prev_tag, tag, prev_type, type_):\n",
        "    # check if a chunk ended between the previous and current word\n",
        "    # arguments: previous and current chunk tags, previous and current types\n",
        "    chunk_end = False\n",
        "\n",
        "    if prev_tag == 'E': chunk_end = True\n",
        "    if prev_tag == 'S': chunk_end = True\n",
        "\n",
        "    if prev_tag == 'B' and tag == 'B': chunk_end = True\n",
        "    if prev_tag == 'B' and tag == 'S': chunk_end = True\n",
        "    if prev_tag == 'B' and tag == 'O': chunk_end = True\n",
        "    if prev_tag == 'I' and tag == 'B': chunk_end = True\n",
        "    if prev_tag == 'I' and tag == 'S': chunk_end = True\n",
        "    if prev_tag == 'I' and tag == 'O': chunk_end = True\n",
        "\n",
        "    if prev_tag != 'O' and prev_tag != '.' and prev_type != type_:\n",
        "        chunk_end = True\n",
        "\n",
        "    # these chunks are assumed to have length 1\n",
        "    if prev_tag == ']': chunk_end = True\n",
        "    if prev_tag == '[': chunk_end = True\n",
        "\n",
        "    return chunk_end\n",
        "\n",
        "def start_of_chunk(prev_tag, tag, prev_type, type_):\n",
        "    # check if a chunk started between the previous and current word\n",
        "    # arguments: previous and current chunk tags, previous and current types\n",
        "    chunk_start = False\n",
        "\n",
        "    if tag == 'B': chunk_start = True\n",
        "    if tag == 'S': chunk_start = True\n",
        "\n",
        "    if prev_tag == 'E' and tag == 'E': chunk_start = True\n",
        "    if prev_tag == 'E' and tag == 'I': chunk_start = True\n",
        "    if prev_tag == 'S' and tag == 'E': chunk_start = True\n",
        "    if prev_tag == 'S' and tag == 'I': chunk_start = True\n",
        "    if prev_tag == 'O' and tag == 'E': chunk_start = True\n",
        "    if prev_tag == 'O' and tag == 'I': chunk_start = True\n",
        "\n",
        "    if tag != 'O' and tag != '.' and prev_type != type_:\n",
        "        chunk_start = True\n",
        "\n",
        "    # these chunks are assumed to have length 1\n",
        "    if tag == '[': chunk_start = True\n",
        "    if tag == ']': chunk_start = True\n",
        "\n",
        "    return chunk_start\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JKCDcMd58SmS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xj36nzZ0sRSD",
        "colab_type": "code",
        "outputId": "7afbb796-afe0-42bc-aa13-b893caabc046",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "cell_type": "code",
      "source": [
        "#Evaluate training results\n",
        "\n",
        "with open('/content/gdrive/Team Drives/cis530/results/train_results.txt') as f:\n",
        "    counts = evaluate(f)\n",
        "report(counts)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processed 157843 tokens with 8675 phrases; found: 8942 phrases; correct: 8487.\n",
            "accuracy:  99.67%; precision:  94.91%; recall:  97.83%; FB1:  96.35\n",
            "            CALLE: precision:  80.58%; recall:  93.27%; FB1:  86.46  757\n",
            "     CENTRO_SALUD: precision:  80.00%; recall: 100.00%; FB1:  88.89  5\n",
            "CORREO_ELECTRONICO: precision:  91.55%; recall:  98.53%; FB1:  94.92  367\n",
            "EDAD_SUJETO_ASISTENCIA: precision:  91.62%; recall:  95.92%; FB1:  93.72  847\n",
            "FAMILIARES_SUJETO_ASISTENCIA: precision:  88.41%; recall:  83.82%; FB1:  86.05  164\n",
            "           FECHAS: precision:  99.90%; recall:  99.49%; FB1:  99.70  983\n",
            "         HOSPITAL: precision:  80.75%; recall:  92.97%; FB1:  86.43  213\n",
            " ID_ASEGURAMIENTO: precision: 100.00%; recall: 100.00%; FB1: 100.00  285\n",
            "ID_CONTACTO_ASISTENCIAL: precision: 100.00%; recall:  98.08%; FB1:  99.03  51\n",
            "ID_SUJETO_ASISTENCIA: precision:  98.82%; recall:  98.82%; FB1:  98.82  424\n",
            "ID_TITULACION_PERSONAL_SANITARIO: precision:  99.15%; recall:  99.72%; FB1:  99.44  355\n",
            "      INSTITUCION: precision:  72.73%; recall:  84.85%; FB1:  78.32  77\n",
            "NOMBRE_PERSONAL_SANITARIO: precision:  97.00%; recall:  99.23%; FB1:  98.11  801\n",
            "NOMBRE_SUJETO_ASISTENCIA: precision:  98.27%; recall:  98.03%; FB1:  98.15  809\n",
            "       NUMERO_FAX: precision:  85.71%; recall:  85.71%; FB1:  85.71  7\n",
            "  NUMERO_TELEFONO: precision:  95.65%; recall: 100.00%; FB1:  97.78  46\n",
            "OTROS_SUJETO_ASISTENCIA: precision:  62.50%; recall:  71.43%; FB1:  66.67  8\n",
            "             PAIS: precision:  96.62%; recall:  99.63%; FB1:  98.10  562\n",
            "        PROFESION: precision:  95.00%; recall:  95.00%; FB1:  95.00  20\n",
            "SEXO_SUJETO_ASISTENCIA: precision:  99.31%; recall:  99.86%; FB1:  99.58  724\n",
            "       TERRITORIO: precision:  96.80%; recall:  99.00%; FB1:  97.89  1437\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5Im2FtrjuK4_",
        "colab_type": "code",
        "outputId": "c08e06fb-c983-4f89-bdf6-72fc4e852029",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "cell_type": "code",
      "source": [
        "#Evaluate dev results\n",
        "\n",
        "with open('/content/gdrive/Team Drives/cis530/results/dev_results.txt') as f:\n",
        "    counts = evaluate(f)\n",
        "report(counts)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processed 74003 tokens with 4332 phrases; found: 4733 phrases; correct: 2968.\n",
            "accuracy:  96.85%; precision:  62.71%; recall:  68.51%; FB1:  65.48\n",
            "            CALLE: precision:  14.31%; recall:  27.59%; FB1:  18.84  615\n",
            "     CENTRO_SALUD: precision:   0.00%; recall:   0.00%; FB1:   0.00  2\n",
            "CORREO_ELECTRONICO: precision:  94.57%; recall:  96.67%; FB1:  95.60  184\n",
            "EDAD_SUJETO_ASISTENCIA: precision:  85.23%; recall:  90.72%; FB1:  87.89  413\n",
            "FAMILIARES_SUJETO_ASISTENCIA: precision:  75.38%; recall:  67.12%; FB1:  71.01  65\n",
            "           FECHAS: precision:  54.85%; recall:  92.74%; FB1:  68.93  908\n",
            "         HOSPITAL: precision:  36.22%; recall:  46.46%; FB1:  40.71  127\n",
            " ID_ASEGURAMIENTO: precision:  56.85%; recall:  62.41%; FB1:  59.50  146\n",
            "ID_CONTACTO_ASISTENCIAL: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\n",
            "ID_EMPLEO_PERSONAL_SANITARIO: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\n",
            "ID_SUJETO_ASISTENCIA: precision:  58.82%; recall:   4.74%; FB1:   8.77  17\n",
            "ID_TITULACION_PERSONAL_SANITARIO: precision:  79.40%; recall:  94.61%; FB1:  86.34  199\n",
            "      INSTITUCION: precision:  17.07%; recall:  11.86%; FB1:  14.00  41\n",
            "NOMBRE_PERSONAL_SANITARIO: precision:  42.15%; recall:  49.34%; FB1:  45.47  446\n",
            "NOMBRE_SUJETO_ASISTENCIA: precision:  56.10%; recall:  59.43%; FB1:  57.72  410\n",
            "       NUMERO_FAX: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\n",
            "  NUMERO_TELEFONO: precision:  43.75%; recall:  31.82%; FB1:  36.84  16\n",
            "OTROS_SUJETO_ASISTENCIA: precision:   0.00%; recall:   0.00%; FB1:   0.00  1\n",
            "             PAIS: precision:  97.71%; recall:  96.24%; FB1:  96.97  262\n",
            "        PROFESION: precision:   0.00%; recall:   0.00%; FB1:   0.00  2\n",
            "SEXO_SUJETO_ASISTENCIA: precision:  97.99%; recall:  99.42%; FB1:  98.70  348\n",
            "       TERRITORIO: precision:  90.58%; recall:  65.62%; FB1:  76.11  531\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ODHOwcngr-ro",
        "colab_type": "code",
        "outputId": "71349165-2e5a-4346-c164-6671c000323a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#Evaluate test results\n",
        "\n",
        "with open('/content/gdrive/Team Drives/cis530/results/test_results.txt') as f:\n",
        "    counts = evaluate(f)\n",
        "report(counts)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processed 66137 tokens with 3522 phrases; found: 3904 phrases; correct: 2405.\n",
            "accuracy:  96.94%; precision:  61.60%; recall:  68.29%; FB1:  64.77\n",
            "            CALLE: precision:  16.18%; recall:  31.23%; FB1:  21.32  519\n",
            "     CENTRO_SALUD: precision:  16.67%; recall:  33.33%; FB1:  22.22  6\n",
            "CORREO_ELECTRONICO: precision:  89.33%; recall:  98.53%; FB1:  93.71  150\n",
            "EDAD_SUJETO_ASISTENCIA: precision:  84.23%; recall:  92.00%; FB1:  87.94  355\n",
            "FAMILIARES_SUJETO_ASISTENCIA: precision:  71.83%; recall:  59.30%; FB1:  64.97  71\n",
            "           FECHAS: precision:  51.86%; recall:  97.67%; FB1:  67.74  727\n",
            "         HOSPITAL: precision:  47.27%; recall:  56.52%; FB1:  51.49  110\n",
            " ID_ASEGURAMIENTO: precision:  46.67%; recall:  54.69%; FB1:  50.36  150\n",
            "ID_CONTACTO_ASISTENCIAL: precision:   0.00%; recall:   0.00%; FB1:   0.00  1\n",
            "ID_SUJETO_ASISTENCIA: precision:  33.33%; recall:   0.61%; FB1:   1.20  3\n",
            "ID_TITULACION_PERSONAL_SANITARIO: precision:  72.73%; recall:  93.43%; FB1:  81.79  176\n",
            "      INSTITUCION: precision:   0.00%; recall:   0.00%; FB1:   0.00  5\n",
            "NOMBRE_PERSONAL_SANITARIO: precision:  41.62%; recall:  50.33%; FB1:  45.56  370\n",
            "NOMBRE_SUJETO_ASISTENCIA: precision:  57.67%; recall:  55.10%; FB1:  56.35  300\n",
            "       NUMERO_FAX: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\n",
            "  NUMERO_TELEFONO: precision:   0.00%; recall:   0.00%; FB1:   0.00  3\n",
            "OTROS_SUJETO_ASISTENCIA: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\n",
            "             PAIS: precision:  96.31%; recall:  95.00%; FB1:  95.65  217\n",
            "        PROFESION: precision:  20.00%; recall:  25.00%; FB1:  22.22  5\n",
            "SEXO_SUJETO_ASISTENCIA: precision:  96.59%; recall: 100.00%; FB1:  98.26  293\n",
            "       TERRITORIO: precision:  87.58%; recall:  65.87%; FB1:  75.19  443\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}