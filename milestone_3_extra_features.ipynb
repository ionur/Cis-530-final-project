{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "milestone-3-extra-features.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "z3R7nQYPkGsz",
        "colab_type": "code",
        "outputId": "625144ad-5d3c-4938-95cc-0ff1b48288b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "cell_type": "code",
      "source": [
        "# Mount your google drive. \n",
        "# Use this to save your PyTorch model for submission\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!mkdir /content/gdrive/Team\\ Drives/cis530\n",
        "#Test drive access. \n",
        "#You should have a test.txt in your Google drive\n",
        "with open('/content/gdrive/Team Drives/cis530/test.txt', 'w') as f:\n",
        "  f.write('This is a test file!')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "mkdir: cannot create directory â€˜/content/gdrive/Team Drives/cis530â€™: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sIaKrm1bQdHl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from nltk.corpus import conll2002\n",
        "from nltk.corpus import cess_esp as cess\n",
        "\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import PassiveAggressiveClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l8OT91hjTc_a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def isApostrophePresent(word):\n",
        "    if \"'\" in word:\n",
        "        return True\n",
        "    return False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kFRisyy4Tdno",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def getfeats(word, postag, o, no_of_features = None):\n",
        "    \"\"\" This takes the word in question and\n",
        "    the offset with respect to the instance\n",
        "    word \"\"\"\n",
        "    o = str(o)\n",
        "    \n",
        "    features = [\n",
        "        \n",
        "        (o + 'word', word),\n",
        "        # TODO: add more features here.\n",
        "        (o + 'word.isupper', any(letter.isupper() for letter in word)),\n",
        "        (o + 'word.len', len(word) ),\n",
        "        (o + 'word.isdigit', any(letter.isdigit() for letter in word))\n",
        "        \n",
        "#         (o + 'isApostrophePresent', isApostrophePresent(word))\n",
        "    ]\n",
        "    return features\n",
        "  \n",
        "    \n",
        "    if( no_of_features != None ):\n",
        "      return features\n",
        "    else:\n",
        "      return features[:no_of_features]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XWE_ZtfUTgQJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def word2features(sent, i , no_of_features = None):\n",
        "    \"\"\" The function generates all features\n",
        "    for the word at position i in the\n",
        "    sentence.\"\"\"\n",
        "    features = []\n",
        "    # the window around the token\n",
        "    featlist = [('bias', 1.0)]\n",
        "    features.extend(featlist)\n",
        "\n",
        "    for o in [-1,0,1]:\n",
        "        if i+o >= 0 and i+o < len(sent):\n",
        "            word = sent[i+o][0]\n",
        "#             postag = sent[i+o][1]\n",
        "            postag = \"unknown\"\n",
        "            featlist = getfeats(word, postag, o, no_of_features)\n",
        "            features.extend(featlist)\n",
        "        elif i+o<0:\n",
        "            featlist = [('BOS', 1)]\n",
        "            features.extend(featlist)\n",
        "        else:\n",
        "            featlist = [('EOS', 1)]\n",
        "            features.extend(featlist)    \n",
        "    return dict(features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c88IAh_K9xI-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def runClassifier(model,no_of_features):\n",
        "    #Gathers the data\n",
        "\n",
        "    #Reports the performance of train/dev/test\n",
        "    train_feats = []\n",
        "    train_labels = []\n",
        "\n",
        "    for sent in train_sents:\n",
        "        for i in range(len(sent)):\n",
        "            feats = word2features(sent,i,no_of_features)\n",
        "            \n",
        "            train_feats.append(feats)\n",
        "            train_labels.append(sent[i][-1])\n",
        "\n",
        "    vectorizer = DictVectorizer()\n",
        "    X_train = vectorizer.fit_transform(train_feats)\n",
        "\n",
        "        \n",
        "    #Fit the data to the model\n",
        "    model.fit(X_train, train_labels)\n",
        "\n",
        "\n",
        "    #Training Data\n",
        "    y_train_pred = model.predict(X_train)\n",
        "\n",
        "    j = 0\n",
        "    print(\"Writing to train_results.txt\")\n",
        "    # format is: word gold pred\n",
        "    with open(\"/content/gdrive/Team Drives/cis530/results/train_results.txt\", \"w\") as out:\n",
        "        for sent in train_sents: \n",
        "            for i in range(len(sent)):\n",
        "                word = sent[i][0]\n",
        "                gold = sent[i][-1]\n",
        "                pred = y_train_pred[j]\n",
        "                j += 1\n",
        "                out.write(\"{}\\t{}\\t{}\\n\".format(word,gold,pred))\n",
        "        out.write(\"\\n\")\n",
        "\n",
        "    #Dev Data\n",
        "    dev_feats = []\n",
        "    dev_labels = []\n",
        "\n",
        "    # switch to test_sents for your final results\n",
        "    for sent in dev_sents:\n",
        "        for i in range(len(sent)):\n",
        "            feats = word2features(sent,i)\n",
        "            dev_feats.append(feats)\n",
        "            dev_labels.append(sent[i][-1])\n",
        "\n",
        "    X_dev = vectorizer.transform(dev_feats)\n",
        "    y_dev_pred = model.predict(X_dev)\n",
        "\n",
        "    j = 0\n",
        "    print(\"Writing to dev_results.txt\")\n",
        "    # format is: word gold pred\n",
        "    with open(\"/content/gdrive/Team Drives/cis530/results/dev_results.txt\", \"w\") as out:\n",
        "        for sent in dev_sents: \n",
        "            for i in range(len(sent)):\n",
        "                word = sent[i][0]\n",
        "                gold = sent[i][-1]\n",
        "                pred = y_dev_pred[j]\n",
        "                j += 1\n",
        "                out.write(\"{}\\t{}\\t{}\\n\".format(word,gold,pred))\n",
        "        out.write(\"\\n\")\n",
        "\n",
        "    #Test Data\n",
        "    test_feats = []\n",
        "    test_labels = []\n",
        "\n",
        "    # switch to test_sents for your final results\n",
        "    for sent in test_sents:\n",
        "        for i in range(len(sent)):\n",
        "            feats = word2features(sent,i)\n",
        "            test_feats.append(feats)\n",
        "            test_labels.append(sent[i][-1])\n",
        "\n",
        "    X_test = vectorizer.transform(test_feats)\n",
        "    y_test_pred = model.predict(X_test)\n",
        "\n",
        "    j = 0\n",
        "    print(\"Writing to test_results.txt\")\n",
        "    # format is: word gold pred\n",
        "    with open(\"/content/gdrive/Team Drives/cis530/results/test_results.txt\", \"w\") as out:\n",
        "        for sent in test_sents: \n",
        "            for i in range(len(sent)):\n",
        "                word = sent[i][0]\n",
        "                gold = sent[i][-1]\n",
        "                pred = y_test_pred[j]\n",
        "                j += 1\n",
        "                out.write(\"{}\\t{}\\t{}\\n\".format(word,gold,pred))\n",
        "        out.write(\"\\n\")\n",
        "        \n",
        "        \n",
        "    #Evaluate training results\n",
        "    print('Train Results for the model',model,' with ',no_of_features,' of features')\n",
        "    \n",
        "    with open('/content/gdrive/Team Drives/cis530/results/train_results.txt') as f:\n",
        "      counts = evaluate(f)\n",
        "    report(counts)\n",
        "    \n",
        "    #Evaluate Dev results\n",
        "    print('Dev Results for the model',model,' with ',no_of_features,' of features')\n",
        "    \n",
        "    with open('/content/gdrive/Team Drives/cis530/results/dev_results.txt') as f:\n",
        "      counts = evaluate(f)\n",
        "    report(counts)\n",
        "    \n",
        "    #Evaluate test results\n",
        "    print('Test Results for the model',model,' with ',no_of_features,' of features')\n",
        "    \n",
        "    with open('/content/gdrive/Team Drives/cis530/results/test_results.txt') as f:\n",
        "      counts = evaluate(f)\n",
        "    report(counts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HIyr1WKDTidh",
        "colab_type": "code",
        "outputId": "a709e466-24a5-4a07-e851-f1e7a2830f4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4437
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "if __name__ == \"__main__\":\n",
        "  \n",
        "    # Load the training data\n",
        "    file = open('/content/gdrive/Team Drives/cis530/ner_tagged_sentences/train_ner_tagged_sentences.pickle','rb')\n",
        "    train_sents = pickle.load(file)\n",
        "    file.close()\n",
        "    \n",
        "    print(\"train_sents len= \", len(train_sents))\n",
        "      \n",
        "    file = open('/content/gdrive/Team Drives/cis530/ner_tagged_sentences/dev_ner_tagged_sentences.pickle','rb')\n",
        "    dev_sents = pickle.load(file)\n",
        "    file.close()\n",
        "    \n",
        "    print(\"dev_sents len= \", len(dev_sents))\n",
        "      \n",
        "    file = open('/content/gdrive/Team Drives/cis530/ner_tagged_sentences/test_ner_tagged_sentences.pickle','rb')\n",
        "    test_sents = pickle.load(file)\n",
        "    file.close()\n",
        "    \n",
        "    print(\"test_sents len= \", len(test_sents))\n",
        "    \n",
        "    no_of_features = 4\n",
        "    models = [LinearSVC(),LinearSVC(C=0.01),LinearSVC(C=10)]\n",
        "    \n",
        "    for model in models:\n",
        "      for i in range(1,no_of_features+1,1):\n",
        "        runClassifier(model,i)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_sents len=  8300\n",
            "dev_sents len=  4048\n",
            "test_sents len=  3231\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Writing to train_results.txt\n",
            "Writing to dev_results.txt\n",
            "Writing to test_results.txt\n",
            "Train Results for the model LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
            "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
            "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
            "     verbose=0)  with  1  of features\n",
            "processed 157843 tokens with 8675 phrases; found: 8942 phrases; correct: 8488.\n",
            "accuracy:  99.67%; precision:  94.92%; recall:  97.84%; FB1:  96.36\n",
            "            CALLE: precision:  80.58%; recall:  93.27%; FB1:  86.46  757\n",
            "     CENTRO_SALUD: precision:  80.00%; recall: 100.00%; FB1:  88.89  5\n",
            "CORREO_ELECTRONICO: precision:  91.55%; recall:  98.53%; FB1:  94.92  367\n",
            "EDAD_SUJETO_ASISTENCIA: precision:  91.74%; recall:  96.04%; FB1:  93.84  847\n",
            "FAMILIARES_SUJETO_ASISTENCIA: precision:  88.41%; recall:  83.82%; FB1:  86.05  164\n",
            "           FECHAS: precision:  99.90%; recall:  99.49%; FB1:  99.70  983\n",
            "         HOSPITAL: precision:  80.75%; recall:  92.97%; FB1:  86.43  213\n",
            " ID_ASEGURAMIENTO: precision: 100.00%; recall: 100.00%; FB1: 100.00  285\n",
            "ID_CONTACTO_ASISTENCIAL: precision: 100.00%; recall:  98.08%; FB1:  99.03  51\n",
            "ID_SUJETO_ASISTENCIA: precision:  98.82%; recall:  98.82%; FB1:  98.82  424\n",
            "ID_TITULACION_PERSONAL_SANITARIO: precision:  99.15%; recall:  99.72%; FB1:  99.44  355\n",
            "      INSTITUCION: precision:  72.73%; recall:  84.85%; FB1:  78.32  77\n",
            "NOMBRE_PERSONAL_SANITARIO: precision:  97.00%; recall:  99.23%; FB1:  98.11  801\n",
            "NOMBRE_SUJETO_ASISTENCIA: precision:  98.27%; recall:  98.03%; FB1:  98.15  809\n",
            "       NUMERO_FAX: precision:  85.71%; recall:  85.71%; FB1:  85.71  7\n",
            "  NUMERO_TELEFONO: precision:  95.65%; recall: 100.00%; FB1:  97.78  46\n",
            "OTROS_SUJETO_ASISTENCIA: precision:  62.50%; recall:  71.43%; FB1:  66.67  8\n",
            "             PAIS: precision:  96.62%; recall:  99.63%; FB1:  98.10  562\n",
            "        PROFESION: precision:  95.00%; recall:  95.00%; FB1:  95.00  20\n",
            "SEXO_SUJETO_ASISTENCIA: precision:  99.31%; recall:  99.86%; FB1:  99.58  724\n",
            "       TERRITORIO: precision:  96.80%; recall:  99.00%; FB1:  97.89  1437\n",
            "Dev Results for the model LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
            "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
            "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
            "     verbose=0)  with  1  of features\n",
            "processed 74003 tokens with 4332 phrases; found: 4775 phrases; correct: 3259.\n",
            "accuracy:  97.44%; precision:  68.25%; recall:  75.23%; FB1:  71.57\n",
            "            CALLE: precision:  18.93%; recall:  36.68%; FB1:  24.97  618\n",
            "     CENTRO_SALUD: precision:   0.00%; recall:   0.00%; FB1:   0.00  7\n",
            "CORREO_ELECTRONICO: precision:  95.08%; recall:  96.67%; FB1:  95.87  183\n",
            "EDAD_SUJETO_ASISTENCIA: precision:  85.61%; recall:  90.46%; FB1:  87.97  410\n",
            "FAMILIARES_SUJETO_ASISTENCIA: precision:  66.18%; recall:  61.64%; FB1:  63.83  68\n",
            "           FECHAS: precision:  69.92%; recall:  92.18%; FB1:  79.52  708\n",
            "         HOSPITAL: precision:  41.86%; recall:  54.55%; FB1:  47.37  129\n",
            " ID_ASEGURAMIENTO: precision:  94.03%; recall:  94.74%; FB1:  94.38  134\n",
            "ID_CONTACTO_ASISTENCIAL: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\n",
            "ID_EMPLEO_PERSONAL_SANITARIO: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\n",
            "ID_SUJETO_ASISTENCIA: precision:  32.12%; recall:  20.85%; FB1:  25.29  137\n",
            "ID_TITULACION_PERSONAL_SANITARIO: precision:  90.11%; recall:  98.20%; FB1:  93.98  182\n",
            "      INSTITUCION: precision:  11.11%; recall:  10.17%; FB1:  10.62  54\n",
            "NOMBRE_PERSONAL_SANITARIO: precision:  52.18%; recall:  65.88%; FB1:  58.24  481\n",
            "NOMBRE_SUJETO_ASISTENCIA: precision:  68.13%; recall:  83.98%; FB1:  75.23  477\n",
            "       NUMERO_FAX: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\n",
            "  NUMERO_TELEFONO: precision:  55.56%; recall:  45.45%; FB1:  50.00  18\n",
            "OTROS_SUJETO_ASISTENCIA: precision:   0.00%; recall:   0.00%; FB1:   0.00  1\n",
            "             PAIS: precision:  98.08%; recall:  96.24%; FB1:  97.15  261\n",
            "        PROFESION: precision:  12.50%; recall:  25.00%; FB1:  16.67  8\n",
            "SEXO_SUJETO_ASISTENCIA: precision:  97.98%; recall:  99.13%; FB1:  98.55  347\n",
            "       TERRITORIO: precision:  90.58%; recall:  68.21%; FB1:  77.82  552\n",
            "Test Results for the model LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
            "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
            "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
            "     verbose=0)  with  1  of features\n",
            "processed 66137 tokens with 3522 phrases; found: 3933 phrases; correct: 2677.\n",
            "accuracy:  97.60%; precision:  68.07%; recall:  76.01%; FB1:  71.82\n",
            "            CALLE: precision:  20.83%; recall:  41.26%; FB1:  27.68  533\n",
            "     CENTRO_SALUD: precision:  12.50%; recall:  33.33%; FB1:  18.18  8\n",
            "CORREO_ELECTRONICO: precision:  89.33%; recall:  98.53%; FB1:  93.71  150\n",
            "EDAD_SUJETO_ASISTENCIA: precision:  84.33%; recall:  91.08%; FB1:  87.57  351\n",
            "FAMILIARES_SUJETO_ASISTENCIA: precision:  65.82%; recall:  60.47%; FB1:  63.03  79\n",
            "           FECHAS: precision:  68.99%; recall:  97.41%; FB1:  80.77  545\n",
            "         HOSPITAL: precision:  46.28%; recall:  60.87%; FB1:  52.58  121\n",
            " ID_ASEGURAMIENTO: precision:  93.98%; recall:  97.66%; FB1:  95.79  133\n",
            "ID_CONTACTO_ASISTENCIAL: precision:   0.00%; recall:   0.00%; FB1:   0.00  1\n",
            "ID_SUJETO_ASISTENCIA: precision:  23.15%; recall:  15.34%; FB1:  18.45  108\n",
            "ID_TITULACION_PERSONAL_SANITARIO: precision:  93.15%; recall:  99.27%; FB1:  96.11  146\n",
            "      INSTITUCION: precision:   5.00%; recall:   2.78%; FB1:   3.57  20\n",
            "NOMBRE_PERSONAL_SANITARIO: precision:  54.55%; recall:  68.63%; FB1:  60.78  385\n",
            "NOMBRE_SUJETO_ASISTENCIA: precision:  67.62%; recall:  83.12%; FB1:  74.57  386\n",
            "       NUMERO_FAX: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\n",
            "  NUMERO_TELEFONO: precision:  25.00%; recall:   8.33%; FB1:  12.50  4\n",
            "OTROS_SUJETO_ASISTENCIA: precision:   0.00%; recall:   0.00%; FB1:   0.00  1\n",
            "             PAIS: precision:  96.77%; recall:  95.45%; FB1:  96.11  217\n",
            "        PROFESION: precision:  20.00%; recall:  25.00%; FB1:  22.22  5\n",
            "SEXO_SUJETO_ASISTENCIA: precision:  96.59%; recall: 100.00%; FB1:  98.26  293\n",
            "       TERRITORIO: precision:  89.04%; recall:  67.57%; FB1:  76.83  447\n",
            "Writing to train_results.txt\n",
            "Writing to dev_results.txt\n",
            "Writing to test_results.txt\n",
            "Train Results for the model LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
            "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
            "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
            "     verbose=0)  with  2  of features\n",
            "processed 157843 tokens with 8675 phrases; found: 8941 phrases; correct: 8488.\n",
            "accuracy:  99.67%; precision:  94.93%; recall:  97.84%; FB1:  96.37\n",
            "            CALLE: precision:  80.58%; recall:  93.27%; FB1:  86.46  757\n",
            "     CENTRO_SALUD: precision:  80.00%; recall: 100.00%; FB1:  88.89  5\n",
            "CORREO_ELECTRONICO: precision:  91.55%; recall:  98.53%; FB1:  94.92  367\n",
            "EDAD_SUJETO_ASISTENCIA: precision:  91.74%; recall:  96.04%; FB1:  93.84  847\n",
            "FAMILIARES_SUJETO_ASISTENCIA: precision:  88.41%; recall:  83.82%; FB1:  86.05  164\n",
            "           FECHAS: precision:  99.90%; recall:  99.49%; FB1:  99.70  983\n",
            "         HOSPITAL: precision:  80.75%; recall:  92.97%; FB1:  86.43  213\n",
            " ID_ASEGURAMIENTO: precision: 100.00%; recall: 100.00%; FB1: 100.00  285\n",
            "ID_CONTACTO_ASISTENCIAL: precision: 100.00%; recall:  98.08%; FB1:  99.03  51\n",
            "ID_SUJETO_ASISTENCIA: precision:  98.82%; recall:  98.82%; FB1:  98.82  424\n",
            "ID_TITULACION_PERSONAL_SANITARIO: precision:  99.15%; recall:  99.72%; FB1:  99.44  355\n",
            "      INSTITUCION: precision:  72.73%; recall:  84.85%; FB1:  78.32  77\n",
            "NOMBRE_PERSONAL_SANITARIO: precision:  97.12%; recall:  99.23%; FB1:  98.17  800\n",
            "NOMBRE_SUJETO_ASISTENCIA: precision:  98.27%; recall:  98.03%; FB1:  98.15  809\n",
            "       NUMERO_FAX: precision:  85.71%; recall:  85.71%; FB1:  85.71  7\n",
            "  NUMERO_TELEFONO: precision:  95.65%; recall: 100.00%; FB1:  97.78  46\n",
            "OTROS_SUJETO_ASISTENCIA: precision:  62.50%; recall:  71.43%; FB1:  66.67  8\n",
            "             PAIS: precision:  96.62%; recall:  99.63%; FB1:  98.10  562\n",
            "        PROFESION: precision:  95.00%; recall:  95.00%; FB1:  95.00  20\n",
            "SEXO_SUJETO_ASISTENCIA: precision:  99.31%; recall:  99.86%; FB1:  99.58  724\n",
            "       TERRITORIO: precision:  96.80%; recall:  99.00%; FB1:  97.89  1437\n",
            "Dev Results for the model LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
            "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
            "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
            "     verbose=0)  with  2  of features\n",
            "processed 74003 tokens with 4332 phrases; found: 4774 phrases; correct: 3258.\n",
            "accuracy:  97.44%; precision:  68.24%; recall:  75.21%; FB1:  71.56\n",
            "            CALLE: precision:  19.12%; recall:  36.68%; FB1:  25.13  612\n",
            "     CENTRO_SALUD: precision:   0.00%; recall:   0.00%; FB1:   0.00  7\n",
            "CORREO_ELECTRONICO: precision:  95.08%; recall:  96.67%; FB1:  95.87  183\n",
            "EDAD_SUJETO_ASISTENCIA: precision:  85.61%; recall:  90.46%; FB1:  87.97  410\n",
            "FAMILIARES_SUJETO_ASISTENCIA: precision:  66.18%; recall:  61.64%; FB1:  63.83  68\n",
            "           FECHAS: precision:  69.92%; recall:  92.18%; FB1:  79.52  708\n",
            "         HOSPITAL: precision:  41.86%; recall:  54.55%; FB1:  47.37  129\n",
            " ID_ASEGURAMIENTO: precision:  94.03%; recall:  94.74%; FB1:  94.38  134\n",
            "ID_CONTACTO_ASISTENCIAL: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\n",
            "ID_EMPLEO_PERSONAL_SANITARIO: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\n",
            "ID_SUJETO_ASISTENCIA: precision:  32.12%; recall:  20.85%; FB1:  25.29  137\n",
            "ID_TITULACION_PERSONAL_SANITARIO: precision:  90.11%; recall:  98.20%; FB1:  93.98  182\n",
            "      INSTITUCION: precision:  11.11%; recall:  10.17%; FB1:  10.62  54\n",
            "NOMBRE_PERSONAL_SANITARIO: precision:  51.54%; recall:  65.88%; FB1:  57.83  487\n",
            "NOMBRE_SUJETO_ASISTENCIA: precision:  68.07%; recall:  83.72%; FB1:  75.09  476\n",
            "       NUMERO_FAX: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\n",
            "  NUMERO_TELEFONO: precision:  55.56%; recall:  45.45%; FB1:  50.00  18\n",
            "OTROS_SUJETO_ASISTENCIA: precision:   0.00%; recall:   0.00%; FB1:   0.00  1\n",
            "             PAIS: precision:  98.08%; recall:  96.24%; FB1:  97.15  261\n",
            "        PROFESION: precision:  12.50%; recall:  25.00%; FB1:  16.67  8\n",
            "SEXO_SUJETO_ASISTENCIA: precision:  97.98%; recall:  99.13%; FB1:  98.55  347\n",
            "       TERRITORIO: precision:  90.58%; recall:  68.21%; FB1:  77.82  552\n",
            "Test Results for the model LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
            "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
            "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
            "     verbose=0)  with  2  of features\n",
            "processed 66137 tokens with 3522 phrases; found: 3929 phrases; correct: 2680.\n",
            "accuracy:  97.61%; precision:  68.21%; recall:  76.09%; FB1:  71.94\n",
            "            CALLE: precision:  20.86%; recall:  41.26%; FB1:  27.72  532\n",
            "     CENTRO_SALUD: precision:  12.50%; recall:  33.33%; FB1:  18.18  8\n",
            "CORREO_ELECTRONICO: precision:  89.33%; recall:  98.53%; FB1:  93.71  150\n",
            "EDAD_SUJETO_ASISTENCIA: precision:  84.33%; recall:  91.08%; FB1:  87.57  351\n",
            "FAMILIARES_SUJETO_ASISTENCIA: precision:  65.82%; recall:  60.47%; FB1:  63.03  79\n",
            "           FECHAS: precision:  68.99%; recall:  97.41%; FB1:  80.77  545\n",
            "         HOSPITAL: precision:  48.33%; recall:  63.04%; FB1:  54.72  120\n",
            " ID_ASEGURAMIENTO: precision:  93.98%; recall:  97.66%; FB1:  95.79  133\n",
            "ID_CONTACTO_ASISTENCIAL: precision:   0.00%; recall:   0.00%; FB1:   0.00  1\n",
            "ID_SUJETO_ASISTENCIA: precision:  23.15%; recall:  15.34%; FB1:  18.45  108\n",
            "ID_TITULACION_PERSONAL_SANITARIO: precision:  93.15%; recall:  99.27%; FB1:  96.11  146\n",
            "      INSTITUCION: precision:   5.88%; recall:   2.78%; FB1:   3.77  17\n",
            "NOMBRE_PERSONAL_SANITARIO: precision:  54.78%; recall:  69.28%; FB1:  61.18  387\n",
            "NOMBRE_SUJETO_ASISTENCIA: precision:  67.62%; recall:  83.12%; FB1:  74.57  386\n",
            "       NUMERO_FAX: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\n",
            "  NUMERO_TELEFONO: precision:  25.00%; recall:   8.33%; FB1:  12.50  4\n",
            "OTROS_SUJETO_ASISTENCIA: precision:   0.00%; recall:   0.00%; FB1:   0.00  1\n",
            "             PAIS: precision:  96.77%; recall:  95.45%; FB1:  96.11  217\n",
            "        PROFESION: precision:  20.00%; recall:  25.00%; FB1:  22.22  5\n",
            "SEXO_SUJETO_ASISTENCIA: precision:  96.59%; recall: 100.00%; FB1:  98.26  293\n",
            "       TERRITORIO: precision:  89.01%; recall:  67.40%; FB1:  76.71  446\n",
            "Writing to train_results.txt\n",
            "Writing to dev_results.txt\n",
            "Writing to test_results.txt\n",
            "Train Results for the model LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
            "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
            "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
            "     verbose=0)  with  3  of features\n",
            "processed 157843 tokens with 8675 phrases; found: 8941 phrases; correct: 8488.\n",
            "accuracy:  99.67%; precision:  94.93%; recall:  97.84%; FB1:  96.37\n",
            "            CALLE: precision:  80.69%; recall:  93.27%; FB1:  86.52  756\n",
            "     CENTRO_SALUD: precision:  80.00%; recall: 100.00%; FB1:  88.89  5\n",
            "CORREO_ELECTRONICO: precision:  91.55%; recall:  98.53%; FB1:  94.92  367\n",
            "EDAD_SUJETO_ASISTENCIA: precision:  91.74%; recall:  96.04%; FB1:  93.84  847\n",
            "FAMILIARES_SUJETO_ASISTENCIA: precision:  88.41%; recall:  83.82%; FB1:  86.05  164\n",
            "           FECHAS: precision:  99.90%; recall:  99.49%; FB1:  99.70  983\n",
            "         HOSPITAL: precision:  80.75%; recall:  92.97%; FB1:  86.43  213\n",
            " ID_ASEGURAMIENTO: precision: 100.00%; recall: 100.00%; FB1: 100.00  285\n",
            "ID_CONTACTO_ASISTENCIAL: precision: 100.00%; recall:  98.08%; FB1:  99.03  51\n",
            "ID_SUJETO_ASISTENCIA: precision:  98.82%; recall:  98.82%; FB1:  98.82  424\n",
            "ID_TITULACION_PERSONAL_SANITARIO: precision:  99.15%; recall:  99.72%; FB1:  99.44  355\n",
            "      INSTITUCION: precision:  72.73%; recall:  84.85%; FB1:  78.32  77\n",
            "NOMBRE_PERSONAL_SANITARIO: precision:  97.00%; recall:  99.23%; FB1:  98.11  801\n",
            "NOMBRE_SUJETO_ASISTENCIA: precision:  98.27%; recall:  98.03%; FB1:  98.15  809\n",
            "       NUMERO_FAX: precision:  85.71%; recall:  85.71%; FB1:  85.71  7\n",
            "  NUMERO_TELEFONO: precision:  95.65%; recall: 100.00%; FB1:  97.78  46\n",
            "OTROS_SUJETO_ASISTENCIA: precision:  62.50%; recall:  71.43%; FB1:  66.67  8\n",
            "             PAIS: precision:  96.62%; recall:  99.63%; FB1:  98.10  562\n",
            "        PROFESION: precision:  95.00%; recall:  95.00%; FB1:  95.00  20\n",
            "SEXO_SUJETO_ASISTENCIA: precision:  99.31%; recall:  99.86%; FB1:  99.58  724\n",
            "       TERRITORIO: precision:  96.80%; recall:  99.00%; FB1:  97.89  1437\n",
            "Dev Results for the model LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
            "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
            "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
            "     verbose=0)  with  3  of features\n",
            "processed 74003 tokens with 4332 phrases; found: 4776 phrases; correct: 3259.\n",
            "accuracy:  97.44%; precision:  68.24%; recall:  75.23%; FB1:  71.56\n",
            "            CALLE: precision:  19.12%; recall:  36.68%; FB1:  25.13  612\n",
            "     CENTRO_SALUD: precision:   0.00%; recall:   0.00%; FB1:   0.00  7\n",
            "CORREO_ELECTRONICO: precision:  95.08%; recall:  96.67%; FB1:  95.87  183\n",
            "EDAD_SUJETO_ASISTENCIA: precision:  85.61%; recall:  90.46%; FB1:  87.97  410\n",
            "FAMILIARES_SUJETO_ASISTENCIA: precision:  66.18%; recall:  61.64%; FB1:  63.83  68\n",
            "           FECHAS: precision:  69.92%; recall:  92.18%; FB1:  79.52  708\n",
            "         HOSPITAL: precision:  41.86%; recall:  54.55%; FB1:  47.37  129\n",
            " ID_ASEGURAMIENTO: precision:  94.03%; recall:  94.74%; FB1:  94.38  134\n",
            "ID_CONTACTO_ASISTENCIAL: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\n",
            "ID_EMPLEO_PERSONAL_SANITARIO: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\n",
            "ID_SUJETO_ASISTENCIA: precision:  32.12%; recall:  20.85%; FB1:  25.29  137\n",
            "ID_TITULACION_PERSONAL_SANITARIO: precision:  90.11%; recall:  98.20%; FB1:  93.98  182\n",
            "      INSTITUCION: precision:  11.11%; recall:  10.17%; FB1:  10.62  54\n",
            "NOMBRE_PERSONAL_SANITARIO: precision:  51.43%; recall:  65.88%; FB1:  57.77  488\n",
            "NOMBRE_SUJETO_ASISTENCIA: precision:  68.13%; recall:  83.98%; FB1:  75.23  477\n",
            "       NUMERO_FAX: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\n",
            "  NUMERO_TELEFONO: precision:  55.56%; recall:  45.45%; FB1:  50.00  18\n",
            "OTROS_SUJETO_ASISTENCIA: precision:   0.00%; recall:   0.00%; FB1:   0.00  1\n",
            "             PAIS: precision:  98.08%; recall:  96.24%; FB1:  97.15  261\n",
            "        PROFESION: precision:  12.50%; recall:  25.00%; FB1:  16.67  8\n",
            "SEXO_SUJETO_ASISTENCIA: precision:  97.98%; recall:  99.13%; FB1:  98.55  347\n",
            "       TERRITORIO: precision:  90.58%; recall:  68.21%; FB1:  77.82  552\n",
            "Test Results for the model LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
            "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
            "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
            "     verbose=0)  with  3  of features\n",
            "processed 66137 tokens with 3522 phrases; found: 3933 phrases; correct: 2679.\n",
            "accuracy:  97.61%; precision:  68.12%; recall:  76.06%; FB1:  71.87\n",
            "            CALLE: precision:  20.86%; recall:  41.26%; FB1:  27.72  532\n",
            "     CENTRO_SALUD: precision:  12.50%; recall:  33.33%; FB1:  18.18  8\n",
            "CORREO_ELECTRONICO: precision:  89.33%; recall:  98.53%; FB1:  93.71  150\n",
            "EDAD_SUJETO_ASISTENCIA: precision:  84.33%; recall:  91.08%; FB1:  87.57  351\n",
            "FAMILIARES_SUJETO_ASISTENCIA: precision:  65.82%; recall:  60.47%; FB1:  63.03  79\n",
            "           FECHAS: precision:  68.99%; recall:  97.41%; FB1:  80.77  545\n",
            "         HOSPITAL: precision:  46.28%; recall:  60.87%; FB1:  52.58  121\n",
            " ID_ASEGURAMIENTO: precision:  93.98%; recall:  97.66%; FB1:  95.79  133\n",
            "ID_CONTACTO_ASISTENCIAL: precision:   0.00%; recall:   0.00%; FB1:   0.00  1\n",
            "ID_SUJETO_ASISTENCIA: precision:  23.15%; recall:  15.34%; FB1:  18.45  108\n",
            "ID_TITULACION_PERSONAL_SANITARIO: precision:  93.15%; recall:  99.27%; FB1:  96.11  146\n",
            "      INSTITUCION: precision:   5.00%; recall:   2.78%; FB1:   3.57  20\n",
            "NOMBRE_PERSONAL_SANITARIO: precision:  54.92%; recall:  69.28%; FB1:  61.27  386\n",
            "NOMBRE_SUJETO_ASISTENCIA: precision:  67.62%; recall:  83.12%; FB1:  74.57  386\n",
            "       NUMERO_FAX: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\n",
            "  NUMERO_TELEFONO: precision:  25.00%; recall:   8.33%; FB1:  12.50  4\n",
            "OTROS_SUJETO_ASISTENCIA: precision:   0.00%; recall:   0.00%; FB1:   0.00  1\n",
            "             PAIS: precision:  96.77%; recall:  95.45%; FB1:  96.11  217\n",
            "        PROFESION: precision:  20.00%; recall:  25.00%; FB1:  22.22  5\n",
            "SEXO_SUJETO_ASISTENCIA: precision:  96.59%; recall: 100.00%; FB1:  98.26  293\n",
            "       TERRITORIO: precision:  89.04%; recall:  67.57%; FB1:  76.83  447\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UyThNPeCr5y-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Evaluation\n",
        "#!/usr/bin/env python\n",
        "\n",
        "# Python version of the evaluation script from CoNLL'00-\n",
        "\n",
        "# Intentional differences:\n",
        "# - accept any space as delimiter by default\n",
        "# - optional file argument (default STDIN)\n",
        "# - option to set boundary (-b argument)\n",
        "# - LaTeX output (-l argument) not supported\n",
        "# - raw tags (-r argument) not supported\n",
        "\n",
        "import sys\n",
        "import re\n",
        "\n",
        "from collections import defaultdict, namedtuple\n",
        "\n",
        "ANY_SPACE = '<SPACE>'\n",
        "\n",
        "class FormatError(Exception):\n",
        "    pass\n",
        "\n",
        "Metrics = namedtuple('Metrics', 'tp fp fn prec rec fscore')\n",
        "\n",
        "class EvalCounts(object):\n",
        "    def __init__(self):\n",
        "        self.correct_chunk = 0    # number of correctly identified chunks\n",
        "        self.correct_tags = 0     # number of correct chunk tags\n",
        "        self.found_correct = 0    # number of chunks in corpus\n",
        "        self.found_guessed = 0    # number of identified chunks\n",
        "        self.token_counter = 0    # token counter (ignores sentence breaks)\n",
        "\n",
        "        # counts by type\n",
        "        self.t_correct_chunk = defaultdict(int)\n",
        "        self.t_found_correct = defaultdict(int)\n",
        "        self.t_found_guessed = defaultdict(int)\n",
        "\n",
        "def parse_args(argv):\n",
        "    import argparse\n",
        "    parser = argparse.ArgumentParser(\n",
        "        description='evaluate tagging results using CoNLL criteria',\n",
        "        formatter_class=argparse.ArgumentDefaultsHelpFormatter\n",
        "    )\n",
        "    arg = parser.add_argument\n",
        "    arg('-b', '--boundary', metavar='STR', default='-X-',\n",
        "        help='sentence boundary')\n",
        "    arg('-d', '--delimiter', metavar='CHAR', default=ANY_SPACE,\n",
        "        help='character delimiting items in input')\n",
        "    arg('-o', '--otag', metavar='CHAR', default='O',\n",
        "        help='alternative outside tag')\n",
        "    arg('file', nargs='?', default=None)\n",
        "    return parser.parse_args(argv)\n",
        "\n",
        "def parse_tag(t):\n",
        "    m = re.match(r'^([^-]*)-(.*)$', t)\n",
        "    return m.groups() if m else (t, '')\n",
        "\n",
        "def evaluate(iterable, options=None):\n",
        "    if options is None:\n",
        "        options = parse_args([])    # use defaults\n",
        "\n",
        "    counts = EvalCounts()\n",
        "    num_features = None       # number of features per line\n",
        "    in_correct = False        # currently processed chunks is correct until now\n",
        "    last_correct = 'O'        # previous chunk tag in corpus\n",
        "    last_correct_type = ''    # type of previously identified chunk tag\n",
        "    last_guessed = 'O'        # previously identified chunk tag\n",
        "    last_guessed_type = ''    # type of previous chunk tag in corpus\n",
        "\n",
        "    for line in iterable:\n",
        "        line = line.rstrip('\\r\\n')\n",
        "\n",
        "        if options.delimiter == ANY_SPACE:\n",
        "            features = line.split()\n",
        "        else:\n",
        "            features = line.split(options.delimiter)\n",
        "\n",
        "        if num_features is None:\n",
        "            num_features = len(features)\n",
        "        elif num_features != len(features) and len(features) != 0:\n",
        "            raise FormatError('unexpected number of features: %d (%d)' %\n",
        "                              (len(features), num_features))\n",
        "\n",
        "        if len(features) == 0 or features[0] == options.boundary:\n",
        "            features = [options.boundary, 'O', 'O']\n",
        "        if len(features) < 3:\n",
        "            raise FormatError('unexpected number of features in line %s' % line)\n",
        "\n",
        "        guessed, guessed_type = parse_tag(features.pop())\n",
        "        correct, correct_type = parse_tag(features.pop())\n",
        "        first_item = features.pop(0)\n",
        "\n",
        "        if first_item == options.boundary:\n",
        "            guessed = 'O'\n",
        "\n",
        "        end_correct = end_of_chunk(last_correct, correct,\n",
        "                                   last_correct_type, correct_type)\n",
        "        end_guessed = end_of_chunk(last_guessed, guessed,\n",
        "                                   last_guessed_type, guessed_type)\n",
        "        start_correct = start_of_chunk(last_correct, correct,\n",
        "                                       last_correct_type, correct_type)\n",
        "        start_guessed = start_of_chunk(last_guessed, guessed,\n",
        "                                       last_guessed_type, guessed_type)\n",
        "\n",
        "        if in_correct:\n",
        "            if (end_correct and end_guessed and\n",
        "                last_guessed_type == last_correct_type):\n",
        "                in_correct = False\n",
        "                counts.correct_chunk += 1\n",
        "                counts.t_correct_chunk[last_correct_type] += 1\n",
        "            elif (end_correct != end_guessed or guessed_type != correct_type):\n",
        "                in_correct = False\n",
        "\n",
        "        if start_correct and start_guessed and guessed_type == correct_type:\n",
        "            in_correct = True\n",
        "\n",
        "        if start_correct:\n",
        "            counts.found_correct += 1\n",
        "            counts.t_found_correct[correct_type] += 1\n",
        "        if start_guessed:\n",
        "            counts.found_guessed += 1\n",
        "            counts.t_found_guessed[guessed_type] += 1\n",
        "        if first_item != options.boundary:\n",
        "            if correct == guessed and guessed_type == correct_type:\n",
        "                counts.correct_tags += 1\n",
        "            counts.token_counter += 1\n",
        "\n",
        "        last_guessed = guessed\n",
        "        last_correct = correct\n",
        "        last_guessed_type = guessed_type\n",
        "        last_correct_type = correct_type\n",
        "\n",
        "    if in_correct:\n",
        "        counts.correct_chunk += 1\n",
        "        counts.t_correct_chunk[last_correct_type] += 1\n",
        "\n",
        "    return counts\n",
        "\n",
        "def uniq(iterable):\n",
        "  seen = set()\n",
        "  return [i for i in iterable if not (i in seen or seen.add(i))]\n",
        "\n",
        "def calculate_metrics(correct, guessed, total):\n",
        "    tp, fp, fn = correct, guessed-correct, total-correct\n",
        "    p = 0 if tp + fp == 0 else 1.*tp / (tp + fp)\n",
        "    r = 0 if tp + fn == 0 else 1.*tp / (tp + fn)\n",
        "    f = 0 if p + r == 0 else 2 * p * r / (p + r)\n",
        "    return Metrics(tp, fp, fn, p, r, f)\n",
        "\n",
        "def metrics(counts):\n",
        "    c = counts\n",
        "    overall = calculate_metrics(\n",
        "        c.correct_chunk, c.found_guessed, c.found_correct\n",
        "    )\n",
        "    by_type = {}\n",
        "    for t in uniq(list(c.t_found_correct) + list(c.t_found_guessed)):\n",
        "        by_type[t] = calculate_metrics(\n",
        "            c.t_correct_chunk[t], c.t_found_guessed[t], c.t_found_correct[t]\n",
        "        )\n",
        "    return overall, by_type\n",
        "\n",
        "def report(counts, out=None):\n",
        "    if out is None:\n",
        "        out = sys.stdout\n",
        "\n",
        "    overall, by_type = metrics(counts)\n",
        "\n",
        "    c = counts\n",
        "    out.write('processed %d tokens with %d phrases; ' %\n",
        "              (c.token_counter, c.found_correct))\n",
        "    out.write('found: %d phrases; correct: %d.\\n' %\n",
        "              (c.found_guessed, c.correct_chunk))\n",
        "\n",
        "    if c.token_counter > 0:\n",
        "        out.write('accuracy: %6.2f%%; ' %\n",
        "                  (100.*c.correct_tags/c.token_counter))\n",
        "        out.write('precision: %6.2f%%; ' % (100.*overall.prec))\n",
        "        out.write('recall: %6.2f%%; ' % (100.*overall.rec))\n",
        "        out.write('FB1: %6.2f\\n' % (100.*overall.fscore))\n",
        "\n",
        "    for i, m in sorted(by_type.items()):\n",
        "        out.write('%17s: ' % i)\n",
        "        out.write('precision: %6.2f%%; ' % (100.*m.prec))\n",
        "        out.write('recall: %6.2f%%; ' % (100.*m.rec))\n",
        "        out.write('FB1: %6.2f  %d\\n' % (100.*m.fscore, c.t_found_guessed[i]))\n",
        "\n",
        "def end_of_chunk(prev_tag, tag, prev_type, type_):\n",
        "    # check if a chunk ended between the previous and current word\n",
        "    # arguments: previous and current chunk tags, previous and current types\n",
        "    chunk_end = False\n",
        "\n",
        "    if prev_tag == 'E': chunk_end = True\n",
        "    if prev_tag == 'S': chunk_end = True\n",
        "\n",
        "    if prev_tag == 'B' and tag == 'B': chunk_end = True\n",
        "    if prev_tag == 'B' and tag == 'S': chunk_end = True\n",
        "    if prev_tag == 'B' and tag == 'O': chunk_end = True\n",
        "    if prev_tag == 'I' and tag == 'B': chunk_end = True\n",
        "    if prev_tag == 'I' and tag == 'S': chunk_end = True\n",
        "    if prev_tag == 'I' and tag == 'O': chunk_end = True\n",
        "\n",
        "    if prev_tag != 'O' and prev_tag != '.' and prev_type != type_:\n",
        "        chunk_end = True\n",
        "\n",
        "    # these chunks are assumed to have length 1\n",
        "    if prev_tag == ']': chunk_end = True\n",
        "    if prev_tag == '[': chunk_end = True\n",
        "\n",
        "    return chunk_end\n",
        "\n",
        "def start_of_chunk(prev_tag, tag, prev_type, type_):\n",
        "    # check if a chunk started between the previous and current word\n",
        "    # arguments: previous and current chunk tags, previous and current types\n",
        "    chunk_start = False\n",
        "\n",
        "    if tag == 'B': chunk_start = True\n",
        "    if tag == 'S': chunk_start = True\n",
        "\n",
        "    if prev_tag == 'E' and tag == 'E': chunk_start = True\n",
        "    if prev_tag == 'E' and tag == 'I': chunk_start = True\n",
        "    if prev_tag == 'S' and tag == 'E': chunk_start = True\n",
        "    if prev_tag == 'S' and tag == 'I': chunk_start = True\n",
        "    if prev_tag == 'O' and tag == 'E': chunk_start = True\n",
        "    if prev_tag == 'O' and tag == 'I': chunk_start = True\n",
        "\n",
        "    if tag != 'O' and tag != '.' and prev_type != type_:\n",
        "        chunk_start = True\n",
        "\n",
        "    # these chunks are assumed to have length 1\n",
        "    if tag == '[': chunk_start = True\n",
        "    if tag == ']': chunk_start = True\n",
        "\n",
        "    return chunk_start\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JKCDcMd58SmS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xj36nzZ0sRSD",
        "colab_type": "code",
        "outputId": "fa8ed7db-ad72-4aaf-f376-22728e2169e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "cell_type": "code",
      "source": [
        "#Evaluate training results\n",
        "\n",
        "with open('/content/gdrive/Team Drives/cis530/results/train_results.txt') as f:\n",
        "    counts = evaluate(f)\n",
        "report(counts)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processed 157843 tokens with 8675 phrases; found: 8990 phrases; correct: 8336.\n",
            "accuracy:  99.50%; precision:  92.73%; recall:  96.09%; FB1:  94.38\n",
            "            CALLE: precision:  68.03%; recall:  83.64%; FB1:  75.03  804\n",
            "     CENTRO_SALUD: precision:  50.00%; recall:  75.00%; FB1:  60.00  6\n",
            "CORREO_ELECTRONICO: precision:  90.13%; recall:  99.12%; FB1:  94.41  375\n",
            "EDAD_SUJETO_ASISTENCIA: precision:  90.86%; recall:  95.80%; FB1:  93.26  853\n",
            "FAMILIARES_SUJETO_ASISTENCIA: precision:  85.71%; recall:  79.77%; FB1:  82.63  161\n",
            "           FECHAS: precision:  99.38%; recall:  98.18%; FB1:  98.78  975\n",
            "         HOSPITAL: precision:  71.89%; recall:  84.32%; FB1:  77.61  217\n",
            " ID_ASEGURAMIENTO: precision:  98.96%; recall: 100.00%; FB1:  99.48  288\n",
            "ID_CONTACTO_ASISTENCIAL: precision: 100.00%; recall:  98.08%; FB1:  99.03  51\n",
            "ID_SUJETO_ASISTENCIA: precision:  98.57%; recall:  97.88%; FB1:  98.22  421\n",
            "ID_TITULACION_PERSONAL_SANITARIO: precision:  98.88%; recall:  99.72%; FB1:  99.29  356\n",
            "      INSTITUCION: precision:  72.86%; recall:  77.27%; FB1:  75.00  70\n",
            "NOMBRE_PERSONAL_SANITARIO: precision:  95.64%; recall:  97.96%; FB1:  96.78  802\n",
            "NOMBRE_SUJETO_ASISTENCIA: precision:  97.66%; recall:  97.66%; FB1:  97.66  811\n",
            "       NUMERO_FAX: precision:  71.43%; recall:  71.43%; FB1:  71.43  7\n",
            "  NUMERO_TELEFONO: precision:  91.30%; recall:  95.45%; FB1:  93.33  46\n",
            "OTROS_SUJETO_ASISTENCIA: precision:  57.14%; recall:  57.14%; FB1:  57.14  7\n",
            "             PAIS: precision:  96.09%; recall:  99.08%; FB1:  97.56  562\n",
            "        PROFESION: precision:  68.42%; recall:  65.00%; FB1:  66.67  19\n",
            "SEXO_SUJETO_ASISTENCIA: precision:  99.03%; recall:  99.72%; FB1:  99.38  725\n",
            "       TERRITORIO: precision:  95.89%; recall:  97.86%; FB1:  96.87  1434\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5Im2FtrjuK4_",
        "colab_type": "code",
        "outputId": "c08e06fb-c983-4f89-bdf6-72fc4e852029",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "cell_type": "code",
      "source": [
        "#Evaluate dev results\n",
        "\n",
        "with open('/content/gdrive/Team Drives/cis530/results/dev_results.txt') as f:\n",
        "    counts = evaluate(f)\n",
        "report(counts)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processed 74003 tokens with 4332 phrases; found: 4733 phrases; correct: 2968.\n",
            "accuracy:  96.85%; precision:  62.71%; recall:  68.51%; FB1:  65.48\n",
            "            CALLE: precision:  14.31%; recall:  27.59%; FB1:  18.84  615\n",
            "     CENTRO_SALUD: precision:   0.00%; recall:   0.00%; FB1:   0.00  2\n",
            "CORREO_ELECTRONICO: precision:  94.57%; recall:  96.67%; FB1:  95.60  184\n",
            "EDAD_SUJETO_ASISTENCIA: precision:  85.23%; recall:  90.72%; FB1:  87.89  413\n",
            "FAMILIARES_SUJETO_ASISTENCIA: precision:  75.38%; recall:  67.12%; FB1:  71.01  65\n",
            "           FECHAS: precision:  54.85%; recall:  92.74%; FB1:  68.93  908\n",
            "         HOSPITAL: precision:  36.22%; recall:  46.46%; FB1:  40.71  127\n",
            " ID_ASEGURAMIENTO: precision:  56.85%; recall:  62.41%; FB1:  59.50  146\n",
            "ID_CONTACTO_ASISTENCIAL: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\n",
            "ID_EMPLEO_PERSONAL_SANITARIO: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\n",
            "ID_SUJETO_ASISTENCIA: precision:  58.82%; recall:   4.74%; FB1:   8.77  17\n",
            "ID_TITULACION_PERSONAL_SANITARIO: precision:  79.40%; recall:  94.61%; FB1:  86.34  199\n",
            "      INSTITUCION: precision:  17.07%; recall:  11.86%; FB1:  14.00  41\n",
            "NOMBRE_PERSONAL_SANITARIO: precision:  42.15%; recall:  49.34%; FB1:  45.47  446\n",
            "NOMBRE_SUJETO_ASISTENCIA: precision:  56.10%; recall:  59.43%; FB1:  57.72  410\n",
            "       NUMERO_FAX: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\n",
            "  NUMERO_TELEFONO: precision:  43.75%; recall:  31.82%; FB1:  36.84  16\n",
            "OTROS_SUJETO_ASISTENCIA: precision:   0.00%; recall:   0.00%; FB1:   0.00  1\n",
            "             PAIS: precision:  97.71%; recall:  96.24%; FB1:  96.97  262\n",
            "        PROFESION: precision:   0.00%; recall:   0.00%; FB1:   0.00  2\n",
            "SEXO_SUJETO_ASISTENCIA: precision:  97.99%; recall:  99.42%; FB1:  98.70  348\n",
            "       TERRITORIO: precision:  90.58%; recall:  65.62%; FB1:  76.11  531\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ODHOwcngr-ro",
        "colab_type": "code",
        "outputId": "71349165-2e5a-4346-c164-6671c000323a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#Evaluate test results\n",
        "\n",
        "with open('/content/gdrive/Team Drives/cis530/results/test_results.txt') as f:\n",
        "    counts = evaluate(f)\n",
        "report(counts)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processed 66137 tokens with 3522 phrases; found: 3904 phrases; correct: 2405.\n",
            "accuracy:  96.94%; precision:  61.60%; recall:  68.29%; FB1:  64.77\n",
            "            CALLE: precision:  16.18%; recall:  31.23%; FB1:  21.32  519\n",
            "     CENTRO_SALUD: precision:  16.67%; recall:  33.33%; FB1:  22.22  6\n",
            "CORREO_ELECTRONICO: precision:  89.33%; recall:  98.53%; FB1:  93.71  150\n",
            "EDAD_SUJETO_ASISTENCIA: precision:  84.23%; recall:  92.00%; FB1:  87.94  355\n",
            "FAMILIARES_SUJETO_ASISTENCIA: precision:  71.83%; recall:  59.30%; FB1:  64.97  71\n",
            "           FECHAS: precision:  51.86%; recall:  97.67%; FB1:  67.74  727\n",
            "         HOSPITAL: precision:  47.27%; recall:  56.52%; FB1:  51.49  110\n",
            " ID_ASEGURAMIENTO: precision:  46.67%; recall:  54.69%; FB1:  50.36  150\n",
            "ID_CONTACTO_ASISTENCIAL: precision:   0.00%; recall:   0.00%; FB1:   0.00  1\n",
            "ID_SUJETO_ASISTENCIA: precision:  33.33%; recall:   0.61%; FB1:   1.20  3\n",
            "ID_TITULACION_PERSONAL_SANITARIO: precision:  72.73%; recall:  93.43%; FB1:  81.79  176\n",
            "      INSTITUCION: precision:   0.00%; recall:   0.00%; FB1:   0.00  5\n",
            "NOMBRE_PERSONAL_SANITARIO: precision:  41.62%; recall:  50.33%; FB1:  45.56  370\n",
            "NOMBRE_SUJETO_ASISTENCIA: precision:  57.67%; recall:  55.10%; FB1:  56.35  300\n",
            "       NUMERO_FAX: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\n",
            "  NUMERO_TELEFONO: precision:   0.00%; recall:   0.00%; FB1:   0.00  3\n",
            "OTROS_SUJETO_ASISTENCIA: precision:   0.00%; recall:   0.00%; FB1:   0.00  0\n",
            "             PAIS: precision:  96.31%; recall:  95.00%; FB1:  95.65  217\n",
            "        PROFESION: precision:  20.00%; recall:  25.00%; FB1:  22.22  5\n",
            "SEXO_SUJETO_ASISTENCIA: precision:  96.59%; recall: 100.00%; FB1:  98.26  293\n",
            "       TERRITORIO: precision:  87.58%; recall:  65.87%; FB1:  75.19  443\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}